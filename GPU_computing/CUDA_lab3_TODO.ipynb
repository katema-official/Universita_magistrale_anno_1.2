{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CUDA_lab3_TODO.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "WoJbB3T5Vkw-",
        "zs_a5Vuimily",
        "ygwWcMU9DJmG",
        "VX7H_0JiBx2j",
        "IkYKd9J32ewH",
        "Dg9BHTaWClBj"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **LAB 3 - Modello di esecuzione CUDA**\n",
        "---"
      ],
      "metadata": {
        "id": "fZYqN0UwVLC_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoJbB3T5Vkw-"
      },
      "source": [
        "# ▶️ CUDA setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fht2Wy8wVkxJ"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jP2H_YJVkxJ"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [GPU Compute Capability](https://developer.nvidia.com/cuda-gpus)"
      ],
      "metadata": {
        "id": "VKbaxH9wWosO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cGSqZovVkxK"
      },
      "source": [
        "## NVCC Plugin for Jupyter notebook\n",
        "\n",
        "*Usage*:\n",
        "\n",
        "\n",
        "*   Load Extension `%load_ext nvcc_plugin`\n",
        "*   Mark a cell to be treated as cuda cell\n",
        "`%%cuda --name example.cu --compile false`\n",
        "\n",
        "**NOTE**: The cell must contain either code or comments to be run successfully. It accepts 2 arguments. `-n | --name` - which is the name of either CUDA source or Header. The name parameter must have extension `.cu` or `.h`. Second argument -c | --compile; default value is false. The argument is a flag to specify if the cell will be compiled and run right away or not. It might be usefull if you're playing in the main function\n",
        "\n",
        "*  We are ready to run CUDA C/C++ code right in your Notebook. For this we need explicitly say to the interpreter, that we want to use the extension by adding `%%cu` at the beginning of each cell with CUDA code. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCVhMkqYVkxK"
      },
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6PDOytTVkxK"
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Bash setup\n",
        "%%writefile /root/.bashrc\n",
        "\n",
        "# If not running interactively, don't do anything\n",
        "[ -z \"$PS1\" ] && return\n",
        "\n",
        "# don't put duplicate lines in the history. See bash(1) for more options\n",
        "# ... or force ignoredups and ignorespace\n",
        "HISTCONTROL=ignoredups:ignorespace\n",
        "\n",
        "# append to the history file, don't overwrite it\n",
        "shopt -s histappend\n",
        "\n",
        "# for setting history length see HISTSIZE and HISTFILESIZE in bash(1)\n",
        "HISTSIZE=10000\n",
        "HISTFILESIZE=20000\n",
        "\n",
        "# check the window size after each command and, if necessary,\n",
        "# update the values of LINES and COLUMNS.\n",
        "shopt -s checkwinsize\n",
        "\n",
        "# make less more friendly for non-text input files, see lesspipe(1)\n",
        "[ -x /usr/bin/lesspipe ] && eval \"$(SHELL=/bin/sh lesspipe)\"\n",
        "\n",
        "PS1='\\[\\033[01;34m\\]\\w\\[\\033[00m\\]\\$ '\n",
        "\n",
        "# enable color support of ls and also add handy aliases\n",
        "if [ -x /usr/bin/dircolors ]; then\n",
        "    test -r ~/.dircolors && eval \"$(dircolors -b ~/.dircolors)\" || eval \"$(dircolors -b)\"\n",
        "    alias ls='ls --color=auto'\n",
        "    #alias dir='dir --color=auto'\n",
        "    #alias vdir='vdir --color=auto'\n",
        "\n",
        "    alias grep='grep --color=auto'\n",
        "    alias fgrep='fgrep --color=auto'\n",
        "    alias egrep='egrep --color=auto'\n",
        "fi\n",
        "\n",
        "# some more ls aliases\n",
        "alias ll='ls -lF'\n",
        "alias la='ls -A'\n",
        "alias l='ls -CF'\n",
        "\n",
        "# path setup\n",
        "export PATH=\"./:/usr/local/cuda/bin:$PATH\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "O8ICSyy8_GEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!source /root/.bashrc"
      ],
      "metadata": {
        "id": "QxIfKO3Ghf7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone GPUcomputing site on github..."
      ],
      "metadata": {
        "id": "EZB5mYG7mwKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/giulianogrossi/GPUcomputing.git"
      ],
      "metadata": {
        "id": "fNqKbfd2l15f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make some paths..."
      ],
      "metadata": {
        "id": "yFuZvv7gnFVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# path setup\n",
        "%cd /content/GPUcomputing/lab3\n",
        "!mkdir -p /content/utils\n",
        "!mkdir -p divergence\n",
        "!mkdir -p histogram\n",
        "!mkdir -p MQDB-CUDA\n",
        "!mkdir -p parReduce"
      ],
      "metadata": {
        "id": "tC-AaOJlkLOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ▶️ VS Code on Colab"
      ],
      "metadata": {
        "id": "zs_a5Vuimily"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Colab-ssh tunnel\n",
        "#@markdown Execute this cell to open the ssh tunnel. Check [colab-ssh documentation](https://github.com/WassimBenzarti/colab-ssh) for more details.\n",
        "\n",
        "# Install colab_ssh on google colab\n",
        "!pip install colab_ssh --upgrade\n",
        "\n",
        "from colab_ssh import launch_ssh_cloudflared, init_git_cloudflared\n",
        "ssh_tunnel_password = \"gpu\" #@param {type: \"string\"}\n",
        "launch_ssh_cloudflared(password=ssh_tunnel_password)\n",
        "\n",
        "# Optional: if you want to clone a Github or Gitlab repository\n",
        "repository_url=\"https://github.com/giulianogrossi/GPUcomputing\" #@param {type: \"string\"}\n",
        "init_git_cloudflared(repository_url)"
      ],
      "metadata": {
        "id": "BCf9JxqphHAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gUDpbz5TZml"
      },
      "source": [
        "# ✅ Divergence analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuIBtkKxcFY6"
      },
      "source": [
        "%%writefile /content/utils/common.h\n",
        "#include <sys/time.h>\n",
        "\n",
        "#ifndef _COMMON_H\n",
        "#define _COMMON_H\n",
        "\n",
        "#define CHECK(call)                                                            \\\n",
        "{                                                                              \\\n",
        "    const cudaError_t error = call;                                            \\\n",
        "    if (error != cudaSuccess)                                                  \\\n",
        "    {                                                                          \\\n",
        "        fprintf(stderr, \"Error: %s:%d, \", __FILE__, __LINE__);                 \\\n",
        "        fprintf(stderr, \"code: %d, reason: %s\\n\", error,                       \\\n",
        "                cudaGetErrorString(error));                                    \\\n",
        "    }                                                                          \\\n",
        "}\n",
        "\n",
        "#define CHECK_CUBLAS(call)                                                     \\\n",
        "{                                                                              \\\n",
        "    cublasStatus_t err;                                                        \\\n",
        "    if ((err = (call)) != CUBLAS_STATUS_SUCCESS)                               \\\n",
        "    {                                                                          \\\n",
        "        fprintf(stderr, \"Got CUBLAS error %d at %s:%d\\n\", err, __FILE__,       \\\n",
        "                __LINE__);                                                     \\\n",
        "        exit(1);                                                               \\\n",
        "    }                                                                          \\\n",
        "}\n",
        "\n",
        "#define CHECK_CURAND(call)                                                     \\\n",
        "{                                                                              \\\n",
        "    curandStatus_t err;                                                        \\\n",
        "    if ((err = (call)) != CURAND_STATUS_SUCCESS)                               \\\n",
        "    {                                                                          \\\n",
        "        fprintf(stderr, \"Got CURAND error %d at %s:%d\\n\", err, __FILE__,       \\\n",
        "                __LINE__);                                                     \\\n",
        "        exit(1);                                                               \\\n",
        "    }                                                                          \\\n",
        "}\n",
        "\n",
        "#define CHECK_CUFFT(call)                                                      \\\n",
        "{                                                                              \\\n",
        "    cufftResult err;                                                           \\\n",
        "    if ( (err = (call)) != CUFFT_SUCCESS)                                      \\\n",
        "    {                                                                          \\\n",
        "        fprintf(stderr, \"Got CUFFT error %d at %s:%d\\n\", err, __FILE__,        \\\n",
        "                __LINE__);                                                     \\\n",
        "        exit(1);                                                               \\\n",
        "    }                                                                          \\\n",
        "}\n",
        "\n",
        "#define CHECK_CUSPARSE(call)                                                   \\\n",
        "{                                                                              \\\n",
        "    cusparseStatus_t err;                                                      \\\n",
        "    if ((err = (call)) != CUSPARSE_STATUS_SUCCESS)                             \\\n",
        "    {                                                                          \\\n",
        "        fprintf(stderr, \"Got error %d at %s:%d\\n\", err, __FILE__, __LINE__);   \\\n",
        "        cudaError_t cuda_err = cudaGetLastError();                             \\\n",
        "        if (cuda_err != cudaSuccess)                                           \\\n",
        "        {                                                                      \\\n",
        "            fprintf(stderr, \"  CUDA error \\\"%s\\\" also detected\\n\",             \\\n",
        "                    cudaGetErrorString(cuda_err));                             \\\n",
        "        }                                                                      \\\n",
        "        exit(1);                                                               \\\n",
        "    }                                                                          \\\n",
        "}\n",
        "\n",
        "inline double seconds() {\n",
        "    struct timeval tp;\n",
        "    struct timezone tzp;\n",
        "    int i = gettimeofday(&tp, &tzp);\n",
        "    return ((double)tp.tv_sec + (double)tp.tv_usec * 1.e-6);\n",
        "}\n",
        "\n",
        "inline void device_name() {\n",
        "    // set up device\n",
        "    int dev = 0;\n",
        "    cudaDeviceProp deviceProp;\n",
        "    CHECK(cudaGetDeviceProperties(&deviceProp, dev));\n",
        "    printf(\"device %d: %s\\n\", dev, deviceProp.name);\n",
        "    CHECK(cudaSetDevice(dev));\n",
        "}\n",
        "\n",
        "typedef unsigned long ulong;\n",
        "typedef unsigned int uint;\n",
        "\n",
        "#endif // _COMMON_H"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlbVvBaXCHBs"
      },
      "source": [
        "%%writefile /content/divergence/div.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <assert.h>\n",
        "#include \"../utils/common.h\"\n",
        "\n",
        "/*\n",
        " * Kernel with warp divergence\n",
        " */\n",
        "__global__ void evenOddDIV(int *c, const ulong N) {\n",
        "\tulong tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\tint a, b;\n",
        "\n",
        "\tif (!(tid % 2))   // branch divergence\n",
        "\t\ta = 2;                  \n",
        "\telse\n",
        "\t\tb = 1;                  \n",
        "\n",
        "\t// check index\n",
        "\tif (tid < N)\n",
        "\t\tc[tid] = a + b;\n",
        "}\n",
        "\n",
        "/*\n",
        " * Kernel without warp divergence\n",
        " */\n",
        "__global__ void evenOddNODIV(int *c, const int N) {\n",
        "\tint tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\tint a = 0, b = 0;\n",
        "\tunsigned int i, twoWarpSize = 2 * warpSize;\n",
        "\n",
        "\tint wid = tid / warpSize; \t// warp index wid = 0,1,2,3,...\n",
        "\tif (!(wid % 2))\n",
        "\t\ta = 2;                  // branch1: thread tid = 0-31, 64-95, ...\n",
        "\telse\n",
        "\t\tb = 1;                  // branch2: thread tid = 32-63, 96-127, ...\n",
        "\n",
        "\t// right index\n",
        "\tif (!(wid % 2))  // even\n",
        "\t\ti = 2 * (tid % warpSize) + (tid / twoWarpSize) * twoWarpSize;\n",
        "\telse            // odd\n",
        "\t\ti = 2 * (tid % warpSize) + 1 + (tid / twoWarpSize) * twoWarpSize;\n",
        "\n",
        "\t// check index\n",
        "\tif (i < N) {\n",
        "\t\tc[i] = a + b;\n",
        "\t}\n",
        "}\n",
        "\n",
        "/*\n",
        " * MAIN\n",
        " */\n",
        "int main(int argc, char **argv) {\n",
        "\n",
        "\t// set up data size\n",
        "\tint blocksize = 1024;\n",
        "\tulong size = 1024*1024;\n",
        "\n",
        "\tif (argc > 1)\n",
        "\t\tblocksize = atoi(argv[1]);\n",
        "\tif (argc > 2)\n",
        "\t\tsize = atoi(argv[2]);\n",
        "\tulong nBytes = size * sizeof(int);\n",
        "\n",
        "\tprintf(\"Data size: %lu  -- \", size);\n",
        "  printf(\"Data size (bytes): %lu MB\\n\", nBytes/1000000);\n",
        "\n",
        "\t// set up execution configuration\n",
        "\tdim3 block(blocksize, 1);\n",
        "\tdim3 grid((size + block.x - 1) / block.x, 1);\n",
        "\tprintf(\"Execution conf (block %d, grid %d)\\nKernels:\\n\", block.x, grid.x);\n",
        "\n",
        "\t// allocate memory\n",
        "\tint *d_C, *C;\n",
        "\tC = (int *) malloc(nBytes);\n",
        "\tCHECK(cudaMalloc((void** )&d_C, nBytes));\n",
        "\n",
        "\t// run kernel 1\n",
        "\tdouble iStart, iElaps;\n",
        "\tiStart = seconds();\n",
        "\tevenOddDIV<<<grid, block>>>(d_C, size);\n",
        "\tCHECK(cudaDeviceSynchronize());\n",
        "\tiElaps = seconds() - iStart;\n",
        "\tprintf(\"\\tevenOddDIV<<<%d, %d>>> elapsed time %f sec \\n\\n\", grid.x, block.x, iElaps);\n",
        "\tCHECK(cudaGetLastError());\n",
        "  \n",
        "  CHECK(cudaMemcpy(C, d_C, nBytes, cudaMemcpyDeviceToHost));\n",
        "\n",
        "\n",
        "\t// run kernel 2\n",
        "  CHECK(cudaMemset(d_C, 0.0, nBytes)); // reset memory\n",
        "\tiStart = seconds();\n",
        "\tevenOddNODIV<<<grid, block>>>(d_C, size);\n",
        "\tiElaps = seconds() - iStart;\n",
        "\tprintf(\"\\tevenOddNODIV<<<%d, %d>>> elapsed time %f sec \\n\\n\", grid.x, block.x, iElaps);\n",
        "\tCHECK(cudaGetLastError());\n",
        "\n",
        "\tCHECK(cudaMemcpy(C, d_C, nBytes, cudaMemcpyDeviceToHost));\n",
        "\n",
        "\tfree(C);\n",
        "\t// free gpu memory and reset device\n",
        "\tCHECK(cudaFree(d_C));\n",
        "\tCHECK(cudaDeviceReset());\n",
        "\treturn EXIT_SUCCESS;\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMEGfjJMcX_e"
      },
      "source": [
        "# Compilazione ed esecuzione\n",
        "!nvcc -arch=sm_37 divergence/div.cu -o div \n",
        "!./div 1024 2000000000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdQqnuH-54Ie"
      },
      "source": [
        "# Compilazione ed esecuzione versione di debug \n",
        "!nvcc -arch=sm_37 -g -G divergence/div.cu -o div_deb\n",
        "!./div_deb 1024 2000000000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygwWcMU9DJmG"
      },
      "source": [
        "# ✅ Parallel Reduction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WThhkz6GDMsm"
      },
      "source": [
        "%%writefile /content/parReduce/preduce.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <assert.h>\n",
        "\n",
        "#include \"../utils/common.h\"\n",
        "\n",
        "/*\n",
        " *  Block by block parallel implementation with divergence (sequential schema)\n",
        " */\n",
        "__global__ void blockParReduce1(int *in, int *out, ulong n) {\n",
        "\n",
        "\tuint tid = threadIdx.x;\n",
        "\tulong idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "\t// boundary check\n",
        "\tif (idx >= n)\n",
        "\t\treturn;\n",
        "\n",
        "\t// convert global data pointer to the local pointer of this block\n",
        "\tint *thisBlock = in + blockIdx.x * blockDim.x;\n",
        "\n",
        "\t// in-place reduction in global memory\n",
        "\tfor (int stride = 1; stride < blockDim.x; stride *= 2) {\n",
        "\t\tif ((tid % (2 * stride)) == 0)\n",
        "\t\t\tthisBlock[tid] += thisBlock[tid + stride];\n",
        "\n",
        "\t\t// synchronize within threadblock\n",
        "\t\t__syncthreads();\n",
        "\t}\n",
        "\n",
        "\t// write result for this block to global mem\n",
        "\tif (tid == 0)\n",
        "\t\tout[blockIdx.x] = thisBlock[0];\n",
        "}\n",
        "\n",
        "/*\n",
        " *  Block by block parallel implementation without divergence (interleaved schema)\n",
        " */\n",
        "__global__ void blockParReduce2(int *in, int *out, ulong n) {\n",
        "\n",
        "\tuint tid = threadIdx.x;\n",
        "\tulong idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "\t// boundary check\n",
        "\tif (idx >= n)\n",
        "\t\treturn;\n",
        "\n",
        "\t// convert global data pointer to the local pointer of this block\n",
        "\tint *thisBlock = in + blockIdx.x * blockDim.x;\n",
        "\n",
        "\t// in-place reduction in global memory\n",
        "\tfor (int stride = blockDim.x / 2; stride > 0; stride >>= 1)  {\n",
        "\t\tif (tid < stride)\n",
        "\t\t\tthisBlock[tid] += thisBlock[tid + stride];\n",
        "\n",
        "\t\t// synchronize within threadblock\n",
        "\t\t__syncthreads();\n",
        "\t}\n",
        "\n",
        "\t// write result for this block to global mem\n",
        "\tif (tid == 0)\n",
        "\t\tout[blockIdx.x] = thisBlock[0];\n",
        "}\n",
        "\n",
        "\n",
        "/*\n",
        " * MAIN: test on parallel reduction\n",
        " */\n",
        "int main(void) {\n",
        "\tint *a, *b, *d_a, *d_b;\n",
        "\tint blockSize = 1024;            // block dim 1D\n",
        "\tulong numBlock = 1024*1024;      // grid dim 1D\n",
        "\tulong n = blockSize * numBlock;  // array dim\n",
        "\tlong sum_CPU = 0, sum_GPU;\n",
        "\tlong nByte = n*sizeof(int), mByte = numBlock * sizeof(int);\n",
        "\tdouble start, stopGPU, stopCPU, speedup;\n",
        "\n",
        "\tprintf(\"\\n****  test on parallel reduction  ****\\n\");\n",
        "\n",
        "\t// init\n",
        "\ta = (int *) malloc(nByte);\n",
        "\tb = (int *) malloc(mByte);\n",
        "\tfor (ulong i = 0; i < n; i++) a[i] = 1;\n",
        "\n",
        "\tCHECK(cudaMalloc((void **) &d_a, nByte));\n",
        "\tCHECK(cudaMemcpy(d_a, a, nByte, cudaMemcpyHostToDevice));\n",
        "\tCHECK(cudaMalloc((void **) &d_b, mByte));\n",
        "\tCHECK(cudaMemset((void *) d_b, 0, mByte));\n",
        "\n",
        "\t/***********************************************************/\n",
        "\t/*                     CPU reduction                       */\n",
        "\t/***********************************************************/\n",
        "\tprintf(\"  Vector length: %.2f MB\\n\",n/(1024.0*1024.0));\n",
        "\tprintf(\"\\n  CPU procedure...\\n\");\n",
        "\tstart = seconds();\n",
        "\tfor (ulong i = 0; i < n; i++) \n",
        "    sum_CPU += a[i];\n",
        "\tstopCPU = seconds() - start;\n",
        "\tprintf(\"    Elapsed time: %f (sec) \\n\", stopCPU);\n",
        "\tprintf(\"    sum: %lu\\n\",sum_CPU);\n",
        "\n",
        "\tprintf(\"\\n  GPU kernels (mem required %lu bytes)\\n\", nByte);\n",
        "\n",
        "\t/***********************************************************/\n",
        "\t/*         KERNEL blockParReduce1 (divergent)              */\n",
        "\t/***********************************************************/\n",
        "\t// block by block parallel implementation with divergence\n",
        "\tprintf(\"\\n  Launch kernel: blockParReduce1...\\n\");\n",
        "\tstart = seconds();\n",
        "\tblockParReduce1<<<numBlock, blockSize>>>(d_a, d_b, n);\n",
        "\tCHECK(cudaGetLastError());\n",
        "\tCHECK(cudaDeviceSynchronize());\n",
        "\tstopGPU = seconds() - start;\n",
        "\tspeedup = stopCPU/stopGPU;\n",
        "\tprintf(\"    Elapsed time: %f (sec) - speedup %.1f\\n\", stopGPU,speedup);\n",
        "\t\n",
        "  // memcopy D2H\n",
        "\tCHECK(cudaMemcpy(b, d_b, mByte, cudaMemcpyDeviceToHost));\n",
        "\t\n",
        "  // check result\n",
        "\tsum_GPU = 0;\n",
        "\tfor (uint i = 0; i < numBlock; i++)\n",
        "\t\tsum_GPU += b[i];\n",
        "\tassert(sum_GPU == n);\n",
        "\n",
        "\t// reset input vector on GPU\n",
        "\tfor (ulong i = 0; i < n; i++) a[i]=1;\n",
        "\tCHECK(cudaMemcpy(d_a, a, nByte, cudaMemcpyHostToDevice));\n",
        "\n",
        "\t/***********************************************************/\n",
        "\t/*        KERNEL blockParReduce2  (non divergent)          */\n",
        "\t/***********************************************************/\n",
        "\t// block by block parallel implementation without divergence\n",
        "\tprintf(\"\\n  Launch kernel: blockParReduce2...\\n\");\n",
        "\tstart = seconds();\n",
        "\tblockParReduce2<<<numBlock, blockSize>>>(d_a, d_b, n);\n",
        "\tCHECK(cudaDeviceSynchronize());\n",
        "\tstopGPU = seconds() - start;\n",
        "\tspeedup = stopCPU/stopGPU;\n",
        "\tprintf(\"    Elapsed time: %f (sec) - speedup %.1f\\n\", stopGPU,speedup);\n",
        "\tCHECK(cudaGetLastError());\n",
        "\t\n",
        "  // memcopy D2H\n",
        "\tCHECK(cudaMemcpy(b, d_b, mByte, cudaMemcpyDeviceToHost));\n",
        "\t\n",
        "  // check result\n",
        "\tsum_GPU = 0;\n",
        "\tfor (uint i = 0; i < numBlock; i++) {\n",
        "\t\tsum_GPU += b[i];\n",
        "  //\t\tprintf(\"b[%d] = %d\\n\",i,b[i]);\n",
        "\t}\n",
        "\tassert(sum_GPU == n);\n",
        "\t\n",
        "  // reset input vector on GPU\n",
        "\tfor (ulong i = 0; i < n; i++) a[i] = 1;\n",
        "\tCHECK(cudaMemcpy(d_a, a, nByte, cudaMemcpyHostToDevice));\n",
        "\n",
        "\t// check result\n",
        "\tsum_GPU = 0;\n",
        "\tfor (uint i = 0; i < numBlock; i++)\n",
        "\t\tsum_GPU += b[i];\n",
        "\tassert(sum_GPU == n);\n",
        "\n",
        "\tcudaFree(d_a);\n",
        "\n",
        "\tCHECK(cudaDeviceReset());\n",
        "\treturn 0;\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIOextPZMiav"
      },
      "source": [
        "#Compilazione ed esecuzione\n",
        "\n",
        "!nvcc -arch=sm_37 parReduce/preduce.cu -o preduce\n",
        "!./preduce"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🔴 TODO"
      ],
      "metadata": {
        "id": "VX7H_0JiBx2j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analizzare le prestazioni usando \n",
        "* `nvprof --events branch,divergent_branch`\n",
        "* `nvprof --metrics achieved_occupancy`"
      ],
      "metadata": {
        "id": "rMXU-CfpCCep"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkYKd9J32ewH"
      },
      "source": [
        "# ✅ Istogramma di un'immagine BMP"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/utils/bmpUtil.h\n",
        "struct imgBMP {\n",
        "\tint width;\n",
        "\tint height;\n",
        "\tunsigned char headInfo[54];\n",
        "\tunsigned long int rowByte;\n",
        "} img;\n",
        "\n",
        "#define\tWIDTHB\t\timg.rowByte\n",
        "#define\tWIDTH\t\timg.width\n",
        "#define\tHEIGHT\t\timg.height\n",
        "#define\tIMAGESIZE\t(WIDTHB*HEIGHT)\n",
        "\n",
        "struct pixel {\n",
        "\tunsigned char R;\n",
        "\tunsigned char G;\n",
        "\tunsigned char B;\n",
        "};\n",
        "\n",
        "typedef unsigned long ulong;\n",
        "typedef unsigned int uint;\n",
        "typedef unsigned char pel;    // pixel element\n",
        "\n",
        "pel *ReadBMPlin(char*);         // Load a BMP image\n",
        "void WriteBMPlin(pel *, char*); // Store a BMP image\n"
      ],
      "metadata": {
        "id": "Jhsz88jl9a4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/utils/ImageStuff.h\n",
        "\n",
        "struct ImgProp {\n",
        "\tint Hpixels;\n",
        "\tint Vpixels;\n",
        "\tunsigned char HeaderInfo[54];\n",
        "\tunsigned long int Hbytes;\n",
        "};\n",
        "\n",
        "struct Pixel {\n",
        "\tunsigned char R;\n",
        "\tunsigned char G;\n",
        "\tunsigned char B;\n",
        "};\n",
        "\n",
        "typedef unsigned char pel;    // pixel element\n",
        "\n",
        "pel** ReadBMP(char*);         // Load a BMP image\n",
        "void WriteBMP(pel**, char*);  // Store a BMP image\n",
        "\n",
        "extern struct ImgProp ip;"
      ],
      "metadata": {
        "id": "W6J2nO9c7Gw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/utils/ImageStuff.c\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <time.h>\n",
        "\n",
        "#include \"ImageStuff.h\"\n",
        "\n",
        "struct ImgProp ip;\n",
        "\n",
        "/*\n",
        " * Load a BMP image\n",
        " */\n",
        "\n",
        "pel** ReadBMP(char* filename) {\n",
        "\tFILE* f = fopen(filename, \"rb\");\n",
        "\tif (f == NULL) {\n",
        "\t\tprintf(\"\\n\\n%s NOT FOUND\\n\\n\", filename);\n",
        "\t\texit(1);\n",
        "\t}\n",
        "\n",
        "\tpel HeaderInfo[54];\n",
        "\tfread(HeaderInfo, sizeof(pel), 54, f); // read the 54-byte header\n",
        "\n",
        "\t// extract image height and width from header\n",
        "\tint width = *(int*) &HeaderInfo[18];\n",
        "\tint height = *(int*) &HeaderInfo[22];\n",
        "\n",
        "\t//copy header for re-use\n",
        "\tfor (unsigned int i = 0; i < 54; i++)\n",
        "\t\tip.HeaderInfo[i] = HeaderInfo[i];\n",
        "\n",
        "\tip.Vpixels = height;\n",
        "\tip.Hpixels = width;\n",
        "\tint RowBytes = (width * 3 + 3) & (~3);\n",
        "\tip.Hbytes = RowBytes;\n",
        "\n",
        "\tprintf(\"\\n   Input BMP File name: %20s  (%u x %u)\", filename, ip.Hpixels, ip.Vpixels);\n",
        "\n",
        "\tpel tmp;\n",
        "\tpel **TheImage = (pel **) malloc(height * sizeof(pel*));\n",
        "\tfor (unsigned int i = 0; i < height; i++)\n",
        "\t\tTheImage[i] = (pel *) malloc(RowBytes * sizeof(pel));\n",
        "\n",
        "\tfor (unsigned int i = 0; i < height; i++)\n",
        "\t\tfread(TheImage[i], sizeof(unsigned char), RowBytes, f);\n",
        "\n",
        "\tfclose(f);\n",
        "\treturn TheImage;  // remember to free() it in caller!\n",
        "}\n",
        "\n",
        "/*\n",
        " * Store a BMP image\n",
        " */\n",
        "void WriteBMP(pel** img, char* filename) {\n",
        "\tFILE* f = fopen(filename, \"wb\");\n",
        "\tif (f == NULL) {\n",
        "\t\tprintf(\"\\n\\nFILE CREATION ERROR: %s\\n\\n\", filename);\n",
        "\t\texit(1);\n",
        "\t}\n",
        "\n",
        "\t//write header\n",
        "\tfor (unsigned int x = 0; x < 54; x++)\n",
        "\t\tfputc(ip.HeaderInfo[x], f);\n",
        "\n",
        "\t//write data\n",
        "\tfor (unsigned int x = 0; x < ip.Vpixels; x++)\n",
        "\t\tfor (unsigned int y = 0; y < ip.Hbytes; y++) {\n",
        "\t\t\tchar temp = img[x][y];\n",
        "\t\t\tfputc(temp, f);\n",
        "\t\t}\n",
        "\n",
        "\tprintf(\"\\n  Output BMP File name: %20s  (%u x %u)\", filename, ip.Hpixels,\n",
        "\t\t\tip.Vpixels);\n",
        "\n",
        "\tfclose(f);\n",
        "}"
      ],
      "metadata": {
        "id": "dB2H-eGY7zBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🔴 TODO"
      ],
      "metadata": {
        "id": "Dg9BHTaWClBj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calcolare l'istogramma di un aimmagine BMP con uso di `atomicAdd`"
      ],
      "metadata": {
        "id": "vfkxkSqmCmAD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G18uZY3t2kFp"
      },
      "source": [
        "%%writefile /content/histogram/hist.cu\n",
        "/**\n",
        " * hist.cu\n",
        " */\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "#include <time.h>\n",
        "#include <limits.h>\n",
        "\n",
        "#include \"/content/utils/ImageStuff.h\"\n",
        "#include \"/content/utils/bmpUtil.h\"\n",
        "#include \"/content/utils/common.h\"\n",
        "\n",
        "/*\n",
        " * Kernel 1D that computes histogram on GPU\n",
        " */\n",
        "__global__ void histogramBMP(uint *bins, const pel *imgSrc, const uint W, const uint H, const uint M) {\n",
        "\t\n",
        "\tint blocksInARow = (W + blockDim.x - 1) / blockDim.x;\n",
        "\tint r = blockIdx.x / blocksInARow;\n",
        "\tint c = ((blockIdx.x % blocksInARow)*blockDim.x + threadIdx.x);\n",
        "\tint trueIndex = r * M + c * 3;\n",
        "\tint R = imgSrc[trueIndex];\n",
        "\tint G = imgSrc[trueIndex + 1];\n",
        "\tint B = imgSrc[trueIndex + 2];\n",
        "\tatomicAdd(&bins[R], 1);\n",
        "\tatomicAdd(&bins[256 + G], 1);\n",
        "\tatomicAdd(&bins[512 + B], 1);\n",
        "\t\n",
        "}\n",
        "\n",
        "/*\n",
        " * Function that computes histogram on CPU\n",
        " */\n",
        "void hist_CPU(uint *bins, const pel *imgSrc, const uint W, const uint H, const uint M) {\n",
        "\tfor (int i = 0; i < W*H; i++) {\n",
        "\t\tuint r = i / W;              // row of the source pixel\n",
        "\t\tuint off = i - r * W;        // col of the source pixel\n",
        "\n",
        "\t\t//  ** byte granularity **\n",
        "\t\tuint p = M * r + 3*off;      // src byte position of the pixel\n",
        "\t\tpel R = imgSrc[p];\n",
        "\t\tpel G = imgSrc[p+1];\n",
        "\t\tpel B = imgSrc[p+2];\n",
        "\t\tbins[R] += 1;\n",
        "\t\tbins[G+256] += 1;\n",
        "\t\tbins[B+512] += 1;\n",
        "\t}\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "\n",
        "\tuint dimBlock = 1024;\n",
        "\tpel *imgBMP_CPU;     // Where images are stored in CPU\n",
        "\tpel *imgBMP_GPU;\t // Where images are stored in GPU\n",
        "\n",
        "\tuint *binsRGB_CPU, *binsRGB_GPU, *binsRGB_GPU2CPU;\n",
        "\tuint N_bins = 3*256;\n",
        "\tuint bin_size = N_bins*sizeof(uint);\n",
        "\n",
        "\tif (argc > 2)\n",
        "\t\tdimBlock = atoi(argv[2]);\n",
        "\telse if (argc < 2) {\n",
        "\t\tprintf(\"\\n\\nUsage:  hist InputFilename dimBlock\\n\");\n",
        "\t\texit(EXIT_FAILURE);\n",
        "\t}\n",
        "\n",
        "\t// bins for CPU & GPU\n",
        "\tbinsRGB_CPU = (uint*) calloc(N_bins, sizeof(uint));\n",
        "\tbinsRGB_GPU2CPU = (uint*) malloc(bin_size);\n",
        "\tCHECK(cudaMalloc((void**) &binsRGB_GPU, bin_size));\n",
        "\n",
        "\t// Create CPU memory to store the input image\n",
        "\timgBMP_CPU = ReadBMPlin(argv[1]);\n",
        "\tif (imgBMP_CPU == NULL) {\n",
        "\t\tprintf(\"Cannot allocate memory for the input image...\\n\");\n",
        "\t\texit(EXIT_FAILURE);\n",
        "\t}\n",
        "\n",
        "\t// Allocate GPU buffer for image and bins\n",
        "\tCHECK(cudaMalloc((void**) &imgBMP_GPU, IMAGESIZE));\n",
        "\n",
        "\t// Copy input vectors from host memory to GPU buffers.\n",
        "\tCHECK(cudaMemcpy(imgBMP_GPU, imgBMP_CPU, IMAGESIZE, cudaMemcpyHostToDevice));\n",
        "\n",
        "\t// CPU histogram\n",
        "\tdouble start = seconds();   // start time\n",
        "\thist_CPU(binsRGB_CPU, imgBMP_CPU, WIDTH, HEIGHT, WIDTHB);\n",
        "\tdouble stop = seconds();   // elapsed time\n",
        "\tprintf(\"\\nCPU elapsed time %f sec \\n\\n\", stop - start);\n",
        "\n",
        "\t// invoke kernels (define grid and block sizes)\n",
        "\tuint nPixels = WIDTH*HEIGHT;\n",
        "\tint dimGrid = (nPixels + dimBlock - 1) / dimBlock;\n",
        "\tprintf(\"\\ndimGrid = %d   dimBlock = %d\\n\",dimGrid,dimBlock);\n",
        "\n",
        "\tstart = seconds();   // start time\n",
        "\n",
        "\thistogramBMP<<<dimGrid, dimBlock>>>(binsRGB_GPU, imgBMP_GPU, WIDTH, HEIGHT, WIDTHB);\n",
        "\t\n",
        "\tCHECK(cudaDeviceSynchronize());\n",
        "\tstop = seconds();   // elapsed time\n",
        "\tprintf(\"\\nGPU elapsed time %f sec \\n\\n\", stop - start);\n",
        "\n",
        "\t// Copy output (results) from GPU buffer to host (CPU) memory.\n",
        "\tCHECK(cudaMemcpy(binsRGB_GPU2CPU, binsRGB_GPU, bin_size, cudaMemcpyDeviceToHost));\n",
        "\n",
        "\tfor (int i = 0; i < N_bins/3; i++)\n",
        "\t\tprintf(\"bin_GPU[%d] = \\t%d\\t%d\\t%d\\t -- bin_CPU[%d] = \\t%d\\t%d\\t%d\\n\", i,\n",
        "\t\t\t\tbinsRGB_GPU2CPU[i],binsRGB_GPU2CPU[i+256],binsRGB_GPU2CPU[i+512],\n",
        "\t\t\t\ti,binsRGB_CPU[i],binsRGB_CPU[i+256],binsRGB_CPU[i+512]);\n",
        "\n",
        "\t// Deallocate GPU memory\n",
        "\tcudaFree(imgBMP_GPU);\n",
        "\tcudaFree(binsRGB_GPU);\n",
        "\n",
        "\t// tracing tools spel as Parallel Nsight and Visual Profiler to show complete traces.\n",
        "\tCHECK(cudaDeviceReset());\n",
        "\n",
        "\treturn (EXIT_SUCCESS);\n",
        "}\n",
        "\n",
        "/*\n",
        " *  Read a 24-bit/pixel BMP file into a 1D linear array.\n",
        " *  Allocate memory to store the 1D image and return its pointer\n",
        " */\n",
        "pel *ReadBMPlin(char* fn) {\n",
        "\tstatic pel *Img;\n",
        "\tFILE* f = fopen(fn, \"rb\");\n",
        "\tif (f == NULL) {\n",
        "\t\tprintf(\"\\n\\n%s NOT FOUND\\n\\n\", fn);\n",
        "\t\texit(EXIT_FAILURE);\n",
        "\t}\n",
        "\n",
        "\tpel HeaderInfo[54];\n",
        "\tsize_t nByte = fread(HeaderInfo, sizeof(pel), 54, f); // read the 54-byte header\n",
        "\t// extract image height and width from header\n",
        "\tint width = *(int*) &HeaderInfo[18];\n",
        "\timg.width = width;\n",
        "\tint height = *(int*) &HeaderInfo[22];\n",
        "\timg.height = height;\n",
        "\tint RowBytes = (width * 3 + 3) & (~3);  // row is multiple of 4 pixel\n",
        "\timg.rowByte = RowBytes;\n",
        "\t//save header for re-use\n",
        "\tmemcpy(img.headInfo, HeaderInfo, 54);\n",
        "\tprintf(\"\\n Input File name: %5s  (%d x %d)   File Size=%lu\", fn, img.width, img.height, IMAGESIZE);\n",
        "\n",
        "\t// allocate memory to store the main image (1 Dimensional array)\n",
        "\tImg = (pel *) malloc(IMAGESIZE);\n",
        "\tif (Img == NULL)\n",
        "\t\treturn Img;      // Cannot allocate memory\n",
        "\t// read the image from disk\n",
        "\tsize_t out = fread(Img, sizeof(pel), IMAGESIZE, f);\n",
        "\tfclose(f);\n",
        "\treturn Img;\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvvbqpV-3gLH"
      },
      "source": [
        "# Compilazione ed esecuzione\n",
        "\n",
        "!nvcc -arch=sm_37 /content/histogram/hist.cu /content/utils/ImageStuff.c -o hist\n",
        "!./hist /content/GPUcomputing/images/dog.bmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOFMQZAkjlLW"
      },
      "source": [
        "# ✅ Prodotto MQDB CUDA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/MQDB-CUDA/mqdb.h\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "#include <math.h>\n",
        "\n",
        "#ifndef MQDB_H\n",
        "#define MQDB_H\n",
        "\n",
        "#define randu() ((float)rand() / (float) RAND_MAX)\n",
        "#define abs(x) ((x)<0 ? (-x) : (x))\n",
        "\n",
        "typedef unsigned long ulong;\n",
        "typedef unsigned int uint;\n",
        "\n",
        "typedef struct MQDB {\n",
        "\tchar desc[100];   // description\n",
        "\tint nBlocks;      // num. of blocks\n",
        "\tint *blkSize;     // block dimensions\n",
        "\tfloat *elem;       // elements in row-major order\n",
        "\tulong nElems;     // actual number of elements\n",
        "} mqdb;\n",
        "\n",
        "// function prototypes\n",
        "int genRandDims(mqdb*, uint, uint, int);\n",
        "int genRandDimsUnified(mqdb*, uint, uint, int);\n",
        "void fillBlocks(mqdb*, uint, uint, char, float);\n",
        "void fillBlocksUnified(mqdb*, uint, uint, char, float);\n",
        "mqdb mqdbConst(uint, uint, uint, float);\n",
        "void mqdbProd(mqdb, mqdb, mqdb);\n",
        "void matProd(mqdb, mqdb, mqdb);\n",
        "void checkResult(mqdb, mqdb);\n",
        "void mqdbDisplay(mqdb*);\n",
        "\n",
        "#endif\n"
      ],
      "metadata": {
        "id": "1fdW1VHR_CGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/MQDB-CUDA/mqdb.cpp\n",
        "#include \"mqdb.h\"\n",
        "\n",
        "/**\n",
        " * random generate block dimensions\n",
        " */\n",
        "int genRandDims(mqdb *M, uint n, uint k, int seed) {\n",
        "\n",
        "\tif (n == 0 || k == 0 || k > n) {\n",
        "\t\tprintf(\"error: n and k must be positive and n > k!\\n\");\n",
        "\t\treturn(-1);\n",
        "\t}\n",
        "\tsrand(seed);\n",
        "\tM->nBlocks = k;\n",
        "\t// random generation of block sizes\n",
        "\tM->blkSize = (int *) malloc(k * sizeof(int));\n",
        "\tint sum = 0;\n",
        "\tint r;\n",
        "\tfloat mu = 2.0f * (float) n / (float) k;\n",
        "\tfor (int i = 0; i < k - 1; i++) {\n",
        "\t\t// expected value E[block_size] = n/k\n",
        "\t\twhile ((r = round(mu * randu())) > n - sum - k + i + 1);\n",
        "\t\tif (!r)\n",
        "\t\t\tr += 1;\n",
        "\t\tM->blkSize[i] = r;\n",
        "\t\tsum += r;\n",
        "\t}\n",
        "\tM->blkSize[k - 1] = n - sum;\n",
        "\treturn(0);\n",
        "}\n",
        "\n",
        "/**\n",
        " * fill blocks either random or constant\n",
        " */\n",
        "void fillBlocks(mqdb *M, uint n, uint k, char T, float c) {\n",
        "\t//mat size n*n\n",
        "\tM->elem = (float *) calloc(n * n, sizeof(float));\n",
        "\tM->nElems = 0;\n",
        "\tint offset = 0;\n",
        "\t// loop on blocks\n",
        "\tfor (int i = 0; i < k; i++) {\n",
        "\t\tfor (int j = 0; j < M->blkSize[i]; j++)\n",
        "\t\t\tfor (int k = 0; k < M->blkSize[i]; k++) {\n",
        "\t\t\t\tif (T == 'C')  \t    // const fill mat entries\n",
        "\t\t\t\t\tM->elem[offset * n + j * n + k + offset] = c;\n",
        "\t\t\t\telse if (T == 'R') \t// random fill mat entries\n",
        "\t\t\t\t\tM->elem[offset * n + j * n + k + offset] = c*randu();\n",
        "\t\t\t\t//printf(\"M->[%d] = %f\\n\", offset * n + j * n + k + offset, M->elem[offset * n + j * n + k + offset]);\n",
        "\t}\n",
        "\t\toffset += M->blkSize[i];\n",
        "\t\tM->nElems += M->blkSize[i]*M->blkSize[i];\n",
        "\t}\n",
        "\t// set description\n",
        "\tsprintf(M->desc, \"Random mqdb:  mat. size = %d, num. blocks = %d\",n,k);\n",
        "}\n",
        "\n",
        "\n",
        "/**\n",
        " * random generate block dimensions - using CUDA Unified Memory\n",
        " */\n",
        "int genRandDimsUnified(mqdb *M, uint n, uint k, int seed) {\n",
        "\n",
        "\tif (n == 0 || k == 0 || k > n) {\n",
        "\t\tprintf(\"error: n and k must be positive and n > k!\\n\");\n",
        "\t\treturn(-1);\n",
        "\t}\n",
        "\tsrand(seed);\n",
        "\tM->nBlocks = k;\n",
        "\tint sum = 0;\n",
        "\tint r;\n",
        "\tfloat mu = 2.0f * (float) n / (float) k;\n",
        "\tfor (int i = 0; i < k - 1; i++) {\n",
        "\t\t// expected value E[block_size] = n/k\n",
        "\t\twhile ((r = round(mu * randu())) > n - sum - k + i + 1);\n",
        "\t\tif (!r)\n",
        "\t\t\tr += 1;\n",
        "\t\tM->blkSize[i] = r;\n",
        "\t\tsum += r;\n",
        "\t}\n",
        "\tM->blkSize[k - 1] = n - sum;\n",
        "\treturn(0);\n",
        "}\n",
        "\n",
        "/**\n",
        " * fill blocks either random or constant - using CUDA Unified Memory\n",
        " */\n",
        "void fillBlocksUnified(mqdb *M, uint n, uint k, char T, float c) {\n",
        "\t//mat size n*n\n",
        "\tM->nElems = 0;\n",
        "\tint offset = 0;\n",
        "\t// loop on blocks\n",
        "\tfor (int i = 0; i < k; i++) {\n",
        "\t\tfor (int j = 0; j < M->blkSize[i]; j++)\n",
        "\t\t\tfor (int k = 0; k < M->blkSize[i]; k++) {\n",
        "\t\t\t\tif (T == 'C')  \t    // const fill mat entries\n",
        "\t\t\t\t\tM->elem[offset * n + j * n + k + offset] = c;\n",
        "\t\t\t\telse if (T == 'R') \t// random fill mat entries\n",
        "\t\t\t\t\tM->elem[offset * n + j * n + k + offset] = c*randu();\n",
        "\t\t\t\t//printf(\"M->[%d] = %f\\n\", offset * n + j * n + k + offset, M->elem[offset * n + j * n + k + offset]);\n",
        "\t}\n",
        "\t\toffset += M->blkSize[i];\n",
        "\t\tM->nElems += M->blkSize[i]*M->blkSize[i];\n",
        "\t}\n",
        "\t// set description\n",
        "\tsprintf(M->desc, \"Random mqdb:  mat. size = %d, num. blocks = %d\",n,k);\n",
        "}\n",
        "\n",
        "/**\n",
        " * rand_gen_mqdb: mqdb  type returned\n",
        " *                n     square matrix size\n",
        " *                k     number of blocks\n",
        " *                seed  seed for random generator\n",
        " */\n",
        "mqdb genRandMat(unsigned n, unsigned k, unsigned seed) {\n",
        "\tmqdb M;\n",
        "\tgenRandDims(&M, n, k, seed);\n",
        "\n",
        "\t// random fill mat entries\n",
        "\tfillBlocks(&M, n, k, 'R', 1.0);\n",
        "\n",
        "\treturn M;\n",
        "}\n",
        "\n",
        "/**\n",
        " * const_mqdb: mqdb  is the type returned\n",
        " *                n     is the square matrix size\n",
        " *                k     is the number of blocks\n",
        " *                seed  is the seed for random generator\n",
        " *                c   \tis the constant value assigned\n",
        " */\n",
        "mqdb mqdbConst(uint n, uint k, uint seed, float c) {\n",
        "\tmqdb M;\n",
        "\tgenRandDims(&M, n, k, seed);\n",
        "\n",
        "\t// fill mat entries with a constant\n",
        "\tfillBlocks(&M, n, k, 'C', c);\n",
        "\n",
        "\treturn M;\n",
        "}\n",
        "\n",
        "/*\n",
        " * product between mqdb matrices restricted to blocks\n",
        " */\n",
        "void mqdbProd(mqdb A, mqdb B, mqdb C) {\n",
        "\tuint n = 0;\n",
        "\tfor (uint i = 0; i < A.nBlocks; i++)\n",
        "\t\tn += A.blkSize[i];                  // mat dim\n",
        "\tint k = A.nBlocks;                      // num blks\n",
        "\tint dl = 0;                             // blk left bound\n",
        "\tint dr = 0;                             // blk right bound\n",
        "\tfor (uint i = 0; i < k; i++) {           // loop on blks\n",
        "\t\tdr += A.blkSize[i];                 // blk right bound\n",
        "\t\tfor (uint r = dl; r < dr; r++) {     // scan block rows\n",
        "\t\t\tfor (uint c = dl; c < dr; c++) { // scan block cols\n",
        "\t\t\t\tfloat s = 0;\n",
        "\t\t\t\tfor (uint l = dl; l < dr; l++)\n",
        "\t\t\t\t\ts += A.elem[r*n + l] * B.elem[c + l * n];\n",
        "\t\t\t\tC.elem[r*n + c] = s;\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t\tdl = dr;\n",
        "\t}\n",
        "}\n",
        "\n",
        "/*\n",
        " * standard (naive) matrix product on host\n",
        " */\n",
        "void matProd(mqdb A, mqdb B, mqdb C) {\n",
        "\tint n = 0;\n",
        "\tfor (uint i = 0; i < A.nBlocks; i++)\n",
        "\t\tn += A.blkSize[i];\n",
        "\n",
        "\tfor (uint r = 0; r < n; r++)\n",
        "\t\tfor (uint c = 0; c < n; c++) {\n",
        "\t\t\tdouble sum = 0;\n",
        "\t\t\tfor (uint l = 0; l < n; l++){\n",
        "\t\t\t\tdouble a = A.elem[r * n + l];\n",
        "\t\t\t\tdouble b = B.elem[l * n + c];\n",
        "\t\t\t\tsum += a*b;\n",
        "\t\t\t}\n",
        "\t\t\tC.elem[r * n + c] = (float)sum;\n",
        "\t\t}\n",
        "}\n",
        "\n",
        "/*\n",
        " * elementwise comparison between two mqdb\n",
        " */\n",
        "void checkResult(mqdb A, mqdb B) {\n",
        "\tdouble epsilon = 1.0E-8;\n",
        "\tbool match = 1;\n",
        "\tint n = 0;\n",
        "\tfor (int i = 0; i < A.nBlocks; i++)\n",
        "\t\tn += A.blkSize[i];\n",
        "\tfor (int i = 0; i < n * n; i++) {\n",
        "\t\tif (abs(A.elem[i] - B.elem[i]) > epsilon) {\n",
        "\t\t\tmatch = 0;\n",
        "\t\t\tprintf(\"   * Arrays do not match!\\n\");\n",
        "\t\t\tprintf(\"     gpu: %2.2f,  host: %2.2f at current %d\\n\", A.elem[i],\n",
        "\t\t\t\t\tB.elem[i], i);\n",
        "\t\t\tbreak;\n",
        "\t\t}\n",
        "\t}\n",
        "\tif (match)\n",
        "\t\tprintf(\"   Arrays match\\n\\n\");\n",
        "}\n",
        "/*\n",
        " * print mqdb\n",
        " */\n",
        "void mqdbDisplay(mqdb *M) {\n",
        "\tint k = M->nBlocks;\n",
        "\tint n = 0;\n",
        "\tprintf(\"%s\\n\", M->desc);\n",
        "\tprintf(\"Block sizes [%d]: \", k);\n",
        "\tfor (int j = 0; j < k; j++) {\n",
        "\t\tn += M->blkSize[j];\n",
        "\t\tprintf(\"%d  \", M->blkSize[j]);\n",
        "\t}\n",
        "\n",
        "\tprintf(\"\\nElements: \\n\");\n",
        "\tfor (int i = 0; i < n; i++) {\n",
        "\t\tfor (int j = 0; j < n; j++) {\n",
        "\t\t\tif (M->elem[i*n + j] == 0)\n",
        "\t\t\t\tprintf(\"------\");\n",
        "\t\t\telse\n",
        "\t\t\t\tprintf(\"%5.2f \", M->elem[i*n + j]);\n",
        "\t\t}\n",
        "\t\tprintf(\"\\n\");\n",
        "\t}\n",
        "\tprintf(\"\\n\");\n",
        "}"
      ],
      "metadata": {
        "id": "lAUf46d5_hLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🔴 TODO"
      ],
      "metadata": {
        "id": "9QunXrnuC8AA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calcolare il prodotto di matrici MQDB con kernel CUDA "
      ],
      "metadata": {
        "id": "lY5KTfZaC82S"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVQVpcvKjkIk"
      },
      "source": [
        "%%writefile /content/MQDB-CUDA/mqdb_prod.cu\n",
        "\n",
        "#include \"/content/MQDB-CUDA/mqdb.h\"\n",
        "#include \"/content/utils/common.h\"\n",
        "\n",
        "#define BLOCK_SIZE 16     // block size\n",
        "\n",
        "struct tms {\n",
        "\tdouble CPUtms;\n",
        "\tdouble GPUtmsNaive;\n",
        "\tdouble GPUtmsMQDB;\n",
        "\tfloat density;\n",
        "};\n",
        "\n",
        "/*\n",
        " * Kernel for standard (naive) matrix product\n",
        " */\n",
        "__global__ void matProd(mqdb A, mqdb B, mqdb C, int n) {\n",
        "\t// row & col indexes\n",
        "\tint row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\tint col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "\t// each thread computes an entry of the product matrix\n",
        "\tif ((row < n) && (col < n)) {\n",
        "\t\tfloat val = 0;\n",
        "\t\tfor (int k = 0; k < n; k++)\n",
        "\t\t\tval += A.elem[row * n + k] * B.elem[k * n + col];\n",
        "\t\tC.elem[row * n + col] = val;\n",
        "\t}\n",
        "}\n",
        "\n",
        "/*\n",
        " * Kernel for block sub-matrix product of mqdb\n",
        " */\n",
        "__global__ void mqdbBlockProd(mqdb A, mqdb B, mqdb C, int offset, int m, int n) {\n",
        "\t\n",
        "\t// ## TODO ##\n",
        "\tint r = offset + blockDim.y * blockIdx.y + threadIdx.y;\n",
        "\tint c = offset + blockDim.x * blockIdx.x + threadIdx.x;\n",
        "\n",
        "\tif(r < n && c < n){\n",
        "\t\tfloat sum = 0;\n",
        "\t\tfor(int i = 0 + offset; i < m + offset; i++){\n",
        "\t\t\t\tsum += A.elem[r*n + i] + B.elem[c + i*n];\n",
        "\t\t}\n",
        "\t\tC.elem[r*n + c] = sum;\n",
        "\t}\n",
        "}\n",
        "\n",
        "/*\n",
        " * Test on MQDB kernels\n",
        " */\n",
        "void testKernelsMQDB(uint n, uint k, struct tms* times) {\n",
        "\n",
        "\t// mqdb host matrices\n",
        "\tmqdb A, B, C, C1;\n",
        "\n",
        "\t// mqdb device matrices\n",
        "\tmqdb d_A, d_B, d_C;\n",
        "\n",
        "\t// fill in\n",
        "\tA = mqdbConst(n, k, 10, 1);\n",
        "\tB = mqdbConst(n, k, 10, 1);\n",
        "\tC = mqdbConst(n, k, 10, 1);\n",
        "\tC1 = mqdbConst(n, k, 10, 1);\n",
        "\n",
        "\tulong nBytes = n * n * sizeof(float);\n",
        "\tulong kBytes = k * sizeof(uint);\n",
        "\tprintf(\"Memory size required = %.1f (MB)\\n\",(float)nBytes/(1024.0*1024.0));\n",
        "\n",
        "\t// malloc and copy on device memory\n",
        "\td_A.nBlocks = A.nBlocks;\n",
        "\tCHECK(cudaMalloc((void**)&d_A.blkSize, kBytes));\n",
        "\tCHECK(cudaMemcpy(d_A.blkSize, A.blkSize, kBytes, cudaMemcpyHostToDevice));\n",
        "\tCHECK(cudaMalloc((void**)&d_A.elem, nBytes));\n",
        "\tCHECK(cudaMemcpy(d_A.elem, A.elem, nBytes, cudaMemcpyHostToDevice));\n",
        "\td_B.nBlocks = B.nBlocks;\n",
        "\tCHECK(cudaMalloc((void**)&d_B.blkSize, kBytes));\n",
        "\tCHECK(cudaMemcpy(d_B.blkSize, B.blkSize, kBytes, cudaMemcpyHostToDevice));\n",
        "\tCHECK(cudaMalloc((void**)&d_B.elem, nBytes));\n",
        "\tCHECK(cudaMemcpy(d_B.elem, B.elem, nBytes, cudaMemcpyHostToDevice));\n",
        "\td_C.nBlocks = C.nBlocks;\n",
        "\tCHECK(cudaMalloc((void**)&d_C.blkSize, kBytes));\n",
        "\tCHECK(cudaMemcpy(d_C.blkSize, C.blkSize, kBytes, cudaMemcpyHostToDevice));\n",
        "\tCHECK(cudaMalloc((void**)&d_C.elem, nBytes));\n",
        "\tCHECK(cudaMemset(d_C.elem, 0.0, nBytes));\n",
        "\n",
        "\t/***********************************************************/\n",
        "\t/*                    CPU MQDB product                     */\n",
        "\t/***********************************************************/\n",
        "\tprintf(\"CPU MQDB product...\\n\");\n",
        "\tdouble start = seconds();\n",
        "\tmqdbProd(A,B,C);\n",
        "\tdouble CPUTime = seconds() - start;\n",
        "\tprintf(\"   CPU elapsed time: %.5f (sec)\\n\\n\", CPUTime);\n",
        "\n",
        "\t/***********************************************************/\n",
        "\t/*                     GPU mat product                     */\n",
        "\t/***********************************************************/\n",
        "\t\n",
        "\tprintf(\"Kernel (naive) mat product...\\n\");\n",
        "\tdim3 block(BLOCK_SIZE, BLOCK_SIZE);\n",
        "\tdim3 grid((n + block.x - 1) / block.x, (n + block.y - 1) / block.y);\n",
        "\tstart = seconds();\n",
        "\tmatProd<<<grid, block>>>(d_A, d_B, d_C, n);\n",
        "\tCHECK(cudaDeviceSynchronize());\n",
        "\tdouble GPUtime1 = seconds() - start;\n",
        "\tprintf(\"   elapsed time:                %.2f (sec)\\n\", GPUtime1);\n",
        "\tprintf(\"   speedup vs CPU MQDB product: %.2f\\n\", CPUTime/GPUtime1);\n",
        "\tCHECK(cudaMemcpy(C1.elem, d_C.elem, nBytes, cudaMemcpyDeviceToHost));\n",
        "\tCHECK(cudaMemset(d_C.elem, 0.0, nBytes));\n",
        "\tcheckResult(C,C1);\n",
        "\t//\tmqdbDisplay(C1);\n",
        "\t\n",
        "\t/***********************************************************/\n",
        "\t/*                     GPU MQDB product                    */\n",
        "\t/***********************************************************/\n",
        "\tprintf(\"Kernel MQDB product...\\n\");\n",
        "\tstart = seconds();\n",
        "\t// TODO\n",
        "\tint offset = 0;\n",
        "\tfor(int i = 0; i < A.nBlocks; i++){\n",
        "\t\t\tint currentSubMatrixDim = A.blkSize[i];\n",
        "\t\t\tdim3 block(BLOCK_SIZE, BLOCK_SIZE);\n",
        "\t \t\tdim3 grid((currentSubMatrixDim + BLOCK_SIZE - 1) / BLOCK_SIZE, \n",
        "\t\t\t           (currentSubMatrixDim + BLOCK_SIZE - 1) / BLOCK_SIZE);\n",
        "\t\t\tmqdbBlockProd<<<grid, block>>>(d_A, d_B, d_C, offset, currentSubMatrixDim, n);\n",
        "\t\t\toffset += currentSubMatrixDim;\n",
        "\n",
        "\t}\n",
        "\n",
        "\t\n",
        "\n",
        "\tCHECK(cudaDeviceSynchronize());\n",
        "\tdouble GPUtime2 = seconds() - start;\n",
        "\tprintf(\"   elapsed time:                    %.2f (sec)\\n\", GPUtime2);\n",
        "\tprintf(\"   speedup vs CPU MQDB product:     %.2f\\n\", CPUTime/GPUtime2);\n",
        "\tprintf(\"   speedup vs GPU std mat product:  %.2f\\n\", GPUtime1/GPUtime2);\n",
        "\t// copy the array 'C' back from the GPU to the CPU\n",
        "\tCHECK(cudaMemcpy(C1.elem, d_C.elem, nBytes, cudaMemcpyDeviceToHost));\n",
        "\tCHECK(cudaMemset(d_C.elem, 0.0, nBytes));\n",
        "\tcheckResult(C,C1);\n",
        "\n",
        "\tCHECK(cudaFree(d_A.elem));\n",
        "\tCHECK(cudaFree(d_B.elem));\n",
        "\tCHECK(cudaFree(d_C.elem));\n",
        "\n",
        "\t// collect times\n",
        "\ttimes->CPUtms = CPUTime;\n",
        "\ttimes->GPUtmsNaive = GPUtime1;\n",
        "\ttimes->GPUtmsMQDB = GPUtime2;\n",
        "\t\n",
        "\tfloat den = 0;\n",
        "\tfor (uint j = 0; j < k; j++)\n",
        "\t\tden += A.blkSize[j]*A.blkSize[j];\n",
        "\ttimes->density = den/(n*n);\n",
        "}\n",
        "\n",
        "/*\n",
        " * main function\n",
        " */\n",
        "int main(int argc, char *argv[]) {\n",
        "\tuint n = 2*1024;      // matrix size\n",
        "\tuint min_k = 30;       // max num of blocks\n",
        "\tuint max_k = 30;       // max num of blocks\n",
        "\n",
        "\tstruct tms times[max_k-min_k+1];\n",
        "\n",
        "\t// multiple tests on kernels\n",
        "\tfor (uint k = min_k; k <= max_k; k++) {\n",
        "\t\tprintf(\"\\n*****   k = %d --- (avg block size = %f)\\n\",k,(float)n/k);\n",
        "\t\ttestKernelsMQDB(n, k, &times[k-min_k]);\n",
        "\t}\n",
        "\n",
        "\tFILE *fd;\n",
        "\tfd = fopen(\"res.csv\", \"w\");\n",
        "\tif (fd == NULL) {\n",
        "\t\tperror(\"file error!\\n\");\n",
        "\t\texit(1);\n",
        "\t}\n",
        "\n",
        "\t// write results on file\n",
        "\tfprintf(fd,\"num blocks,\");\n",
        "\t\tfor (uint j = 0; j <= max_k-min_k; j++)\n",
        "\t\t\tfprintf(fd,\"%d,\",j+min_k);\n",
        "\n",
        "\tfprintf(fd,\"\\nCPU MQDB product,\");\n",
        "\tfor (uint j = 0; j <= max_k-min_k; j++)\n",
        "\t\tfprintf(fd,\"%.4f,\",times[j].CPUtms);\n",
        "\n",
        "\tfprintf(fd,\"\\nKernel mat product naive,\");\n",
        "\tfor (uint j = 0; j <= max_k-min_k; j++)\n",
        "\t\tfprintf(fd,\"%.4f,\",times[j].GPUtmsNaive);\n",
        "\n",
        "\tfprintf(fd,\"\\nKernel MQDB product,\");\n",
        "\tfor (uint j = 0; j <= max_k-min_k; j++)\n",
        "\t\tfprintf(fd,\"%.4f,\",times[j].GPUtmsMQDB);\n",
        "\n",
        "\tfprintf(fd,\"\\ndensity,\");\n",
        "\tfor (uint j = 0; j <= max_k-min_k; j++)\n",
        "\t\tfprintf(fd,\"%.4f,\",times[j].density);\n",
        "\n",
        "\tfclose(fd);\n",
        "\n",
        "\treturn 0;\n",
        "}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLxZjCx8bT3s"
      },
      "source": [
        "# Compilazione ed esecuzione\n",
        "\n",
        "!nvcc -arch=sm_37 /content/MQDB-CUDA/mqdb_prod.cu /content/MQDB-CUDA/mqdb.cpp -o mqdb_prod\n",
        "!./mqdb_prod"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}