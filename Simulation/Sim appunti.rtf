{\rtf1\ansi\ansicpg1252\deff0\nouicompat\deflang1040{\fonttbl{\f0\fnil\fcharset0 Calibri;}}
{\*\generator Riched20 10.0.22000}\viewkind4\uc1 
\pard\sa200\sl276\slmult1\qc\f0\fs44\lang16 Simulation - Appunti\par

\pard\sa200\sl276\slmult1\qj\fs22 Lezione 1 - 01/03/2022\par
Alberto Ceselli. What is simulation? Each time we see something in a computer, it is simulated. The question is: how do I make computations out of a simulated object? For the Oxford Dictionary, a simulation is "the production of a computer \b model \b0 of something, especially for the purpose of study". With something, we usually mean a real world process. So, the simulation deals with? 3D objects? graphics? Something to study? Parallel worlds? In our course, simulation will be a descriptive model. We want to pick a real world system and produce a representation, a simulation, of it. For handling such a system, we need a descriptive model of the system. We can use a function to describe the trajectory of the ball. So, descriptive model: we go froma  complex system to a matemathical representation (simpler) of it. Now, models have different models. Different systems implies different types of models. Like, imagine describing a line of people that is waiting for a service. Another important part is wether the system we want to simulate is deterministic or not (most of the time it is not deterministic). In those cases, we just considers the parts of the system that are interesting for us, then we approximate it and define the connections between it and the rest of the world and then apporixmate some details with a stocasthic component. A descriptive model is usually a formula that, given some variables, describe the model.\par
We need descriptive models, that are languages, to tell to a computer the details of a complex systems. We use them to replicate the details and tell the pc the details of the system. So, the second aim of our course will be to use simulations to study systems and evaluate the results. Why doing simulation though? Because by modeling a certain system, we are forced to have a clear understanding of the system, and so we understand it better. We also have a cheap way to make experiments on that model, and those experiments will resemble the ones we'd do on the real world (but in the sim they are cheaper). We can also visualize the behavior of the system when a parameter changes (what-if analyses). Or we can do the same thing by even changing the whole model for the system. We can use it also to visualize results for complex methods. We also have to consider that the results we get in the simulation can be different from the ones in the real system.\par
After the model has been built, we can get algorithms to do something with our model. Sometimes, they give to analytical problems a solution in closed form. Also, what-if analyses are good when there are not too many cases to test. [A prescriptive model is: given a model and a goal, tell me the best behavior].\par
A basic simulation is the Game of Life (Conway, 1970). First observation: a model must be precise about the description of its system. We modelers will use a simplify assumptions: the individuals live in a matrix. In each cell, there is either an empty or full space (no individual or one). Another observation: do we take time into account? How? In this case, both space and time are discretized.\par
Now, we want to get this model into a computer and see something running. We want to answer some questions, for example.\par
How do we make sure that repetition of stocastic simulations make sense overall?\par
In a simulation, we are interested in qualitative and quantitavie analysis (it depends on the simulation).\par
The simulation paradigms that we will see in this course are: discrete events, agent-based and system dynamics. On the practical side, we'll analyse those three paradigms. All of them contain a stocastic component, on their inner part. \par
Discrete events: the system proceeds at steps, discrete steps, and during those specific points in time we have some interesting things that can happen. \par
Agent-based simulations: we imagine that the agens are independent one another. Each of them has a certain logic, and simulationg means to have them comunicate to do more complex things.\par
System Dynamics: we model our system with stocks, flows, delays and feedback loops. \par
We'll see mostly how to use, but also how to build, a simulation. \par
Sheldon M Ross "Simulation", 5th edition, elsevier pubs (2012).\par
acesellis.ariel.ctu.unimi.it\par
\par
Lezione 2 - 08/03/2022\par
Tre modelli: descrittivi, predittivi, prescrittivi (?).\par
Qui ci interessano quelli descrittivi.\par
Random Variables. Last time, we discussed about descriptive modelling: the idea of trying tor eplicate the behavior of a real system in a computer by means of models representig its key features. Simulation is the idea to exploit those descriptive models to perform, on a PC, checks that we would otherwise do on a real system, and would cost more. There are different phylosofies to build models, and we'll see three techniques, all based on the idea we can approximate the behavior of a complex system by a stocasthic component. So, we'll see three paradigms for modeling using stocastic components. Today, it will still be in part an introduction to the course, but also an intro to the discrete events models. So, let's start with an example. Let's think about y = f(x). How many variable there are here? Two, x and y. It's just an equation, and for the modeler this equation has a special meaning: x is the input data/parameters, that is, something i know or can mention or rely on, thati I image to be meaningful for my experiments. f is the description of a process. y is an abstraction of the process modeled by f. So, y is representing the abstraction of the process modeled by f. f is modeling a process in every bit of detail. Given x, f gives as ouotput something, the result of an observation of our system. We are missing something on f: when we apply it to x, we might get some observation out of the model. In a deterministic world, we call x and y a pair of dependent or independent variables. In our case, y depends upon x. y is called a random variable. We want to look at y as something that is independent from f and x. For traditional variables, when we observe them multiple times, we see a value, a number. For a random variable, when we observe it multiple times, we observe different values/numbers. But different values don't mean white noise. According to f, how we model systems, y becomes a random variable that models something. Sometimes we can define f easily starting from some rules, sometimes it is not so simple. Our goal is anyway to put together rules to obtain f. The overall result of our descriptive modeling of a system is a huge random variable, generally speaking. Our descriptive models will give us random variables that are huge, complex. (the example is taken from the Simulation textbook) (introduction 2 page 23, pharmacist).\par
Our descriptive modeling consists on giving a description of the system, and the descriptive model is just our random variable. Our description of the system is f. To answer different questions, we will have to measure different points of our models, that introduce different random vaiables, one for each question. The model we build, anyway, is constructed based on the questions we are trying to answer. Can we build a deterministic model out of those specifications? The answer it's kind of phylosofical. If I know all the possible positions of people in the world and their need, I can. But practically, I can't. So, we want some averaged values. We have to approximate parts of our system. There are two main point where we do those approximation. One point is the link of our system to the outside world. We want to model a system, the pharmacy, that is linked to the outside world. So, let's approximate the connectors of the system to the outside world. Second point to approximate: the details of the system otself that are not crucial for our study. For example, we are not specifically intereset in the process of making a prescription: I just want to know how long does it take to do that. But how do we approximate those things? by means of other, simpler, random variables. So, for our model, we define the system, we find the connectors and define them as random variables. We then define key components of the system as random variables, that will define those components. In our example, we'll have a random variable that will model at which our does the pharmacist go back home. \par
A connector here can be the process of prescriptions arriving to the pharmacy (Prescriptions arriving). The "filling in process", instead, is something that models our process of filling a prescription. Now we have to transform the labels into some matemathical entities, like random variables. A common assumption is that the individuals of the outside world act randomly. If I observe that a prescription has arrived, I can't tell that another prescription will arrive soon. Each prescription comes independently from the others. The number of arriving prescription is an exponential random variable (let's take it for good rn). The good thing is that they are very easy to simulate, we have efficient algorithms for them. Now, let's take a look to the filling in process. What variable is it? A gaussian one? We can assume it. So, the filling in process if or us a normal random variable. We also know a lot of things about them. We can simulate them too. \par
The time between one and the next is how we model our "prescription arriving". The filling in process, instead, is the time it takes to complete one prescription after starting to work on it. \par
\par
Lezione 3 - 11/03/2022\par
Descrittivo, predittivo e prescrittivo. Simulation, AI e RO (per Davide). \par
Connectors are used for the arrivar of prescriptions, for "internal" things... we don't know an appropriate term. \par
We were in the middle of an example of a descriptive model and simulation task. We want to answer some questions starting from some facts. We can't model the description fully: we have to approximate the model. To approximate, we use stochastic components, for connectors to the outside world and processes. \par
Discrete event modeling: interesting things happen only in specific moments in time.\par
In this course, we will first build the model and then analyze the result.\par
Question 5: what if analysis.\par
\par
Lezione 4 - 15/03/2022\par
\par
Introduction ot Probability and statistics for engineers and scientists (Sheldon M. Ross, book). Idk why it's here (even if I imagine). \par
Discrete Event Simulation - Our first kind of approach for describing a certain environment. The connectors and inner components of the model we've seen are described as random variables for example. \par
Recall: when handling probabilities, we first of all imagine to have a Sample Space, that is, all the possible outcomes of an experiment. An Event, instead, is a particular outcome (or a set of outcomes) of the Sample Space. Also the ideas of Complement of an Event, union and intersection of sets and mutually excluusive events are important for probability and statistics. Two events are mutually exclusive if their intersection is empty. If some events are mutually exclusive events, then the probability of their union is the sum of their probabilities.\line Conditional probability: P(A|B) = probability of A to happen knowing B happened before. It is defined as the probability of A and B happening divided by the probability of B happening. \line Also, P(A) = P(A|B)P(B) + P(A|notB)P(notB). The conditioning events (in this case, B and notB) MUST be such that the sum of their probabilities is one, and they ALL must be mutually exclusive.\par
y=f(x). For a modeler, x is input data, while y is an abstraction of the process modeled by f().\par
Random variables: say you have an experiment, whose output is X. X is a variable, assuming to contain the result of your experiment. If the experiment involves some stochastic behavior, the content of X will always be uncertain. X, then, is called random varibale, that can be discrete or continuous. It can be a single outcome or a set of outcomes. \par
Cumulative Distribution Function: a function F(x) = P(X <= x). [Cumulative because the probabilities sum up, they cumulate!!!]. If X is discrete, we can define another function, the Probability Mass Function: p(x) = P(X = x). The sum of all p(x_i) for all i is 1. In the case of a continuous X variable, we have a (non negative) Probability Density Function such that, for C in R, P(X belongs to C) = Integrale su C di F(x) dx.\par
\par
Lezione 5 - 18/03/2022\par
We are revising elements of probability and statistics. Next friday, anylogic for agent based simulation. So, independent event and independent random variables. We say that two events are independent using the terms of conditional probability. A and B are independent if P(A|B) = P(A). That is, B doesn't give me any information about the happening of A. For example, the flipping of the coin: the second flipping is independent from the first. \line Independent Random Variable: they are defined in terms of independent events. They are independent if P(X belongs to C, Y belongs to D) = P(X belongs to C) * P(Y belongs to D).\line\i Questions, comments...? good.\par
\i0 With the random variables, we can make computations. We can build CDF! Mass, Density... and also some particular parameters. The most famous one is the so-called \b expected value\b0 . E[X] is the sum of all the n possible different values that the variable can take times the probability that the variable will have that value. We have a similar definition for the continuous random variable, where, instead of a sum, we have an integral. The Expected Value is a measure about the tendency of the variable. The Expected value has some important properties: the first one is linearity. That means that E[a*X + b] = a E[X] + b. And E[sum from i=1 to n for X_i] = sum from i=1 to n of E[X_i].\line And also, if g() is a generic funxtion, E[g(X)] = sum from i=1 to n of g(X_i) * p(X_i).\par
Expectation is not the only parameter we compute about random variables. another important parameter is Variance. The Variance is a dispersion measure, not a central tendency as E. Basically, it tells me how far i can expect to find single expectations of my random variable from the expectation. Low variance means: repeated observations of a random variable will produce similar results. High variance means multiple observations of the variable will hold more different values (all around the expected value). Median, Mode etc.. are other Expected Value parameters. And there are "variants" also of the Variance (lol), that is, measures of the dispersion of a single random variable.\line If the E of X is mu, the variance is defined as the error that i get by measuring X and confronting it in respect to mu.\par
Covariance: Cov[X, Y] is higher when the two variables are "very similar", that means, then X is high, Y is also high. Same goes for low.  [Michele: The covariance tells us about not how one interacts with each other, but how they behave in respect to their respective Expected Value]. The Covariance instead is low when the two variables are "opposite": when one is high, the other is low. When the two variables are independent, the Covariance is 0.\par
Normalization of the covariance is called Correlation:\line Corr[X,Y] = Cov[X,Y] / sqrt(Var[X] * Var[Y]). This value always falls between -1 and 1. It does not contain any "new" kind of information in respect to the covariance. It's just scaling the Covariance. 1 = Perfect coorelation of the two variables. If one is high, the other one is high. Same for low. -1 = Perfect opposite correlation of the two variables. 0 = the two variables are not correlated. Knowing one doesn't tell me anything about the other. \par
Markov's Inequality: say X is a random variable, an arbitrary one, assuming it takes only nonnegative values. Then, for any constant a > 0: P(X >= a) <= E[X] / a\par
Chebishev's Inequality: if X takes only nonnegative values, has expectations mu and variance sigma^2. Then, for any k > 0,\line P(|X - mu| >= k*sigma) <= 1/k^2\par
the probability of finding this difference to be large is not arbitrarily large, but instead is bounded. The further I go from the expected value, the lower my probability of having that outcome. The larger the sigma, the lower the k we need for reaching a bound (1/k^2) that is large. \par
\par
Lezione 6 - 22/03/2022\par
The idea behind the theory we are studying is that those stocasthic models are in some awy useful, or, at least, affordable (affidabili). We can use them in our models. In general, knowing the distribution of a function can be enough. But usually, central tendency and dispersion (for us, Expected value and Variance) are important as well of course. The complex variables we'll see in our models will be complex results that can't be expressed analitically. \par
Law of large numbers (weak). Let's consider a sequence of random variables X1, X2, ..., Xn. The type of this random variables is not important (we don't care about their distributions). Let's just say that they are independent and identically distributed (so, the distribution can be whatever, but that distribution must be applied to all those variables). [i.i.d. = indepentend identically distributed]. Even if I don't know the distribution i'm good to go, as long as all random variables have the same distribution. Well, that said, for any eta > 0, and if mu is the expected value of one of those variables [conclusions after sorry] (they have the same identical distribution). Mean vs expected value: mean is the sum over n of Xi all divided by n. Is basically the mean of the red values. Conclusion: the probability that this difference is higher than eta goes to zero as n tends to infinite. This concept comes into play when my random variables X1, ..., Xn are really n readings of the same random variable, or n outcomes of the same experiment. The more experiments we do, the more the mean value we compute matches the expected value of the "basic" random variable. The strong law of large numbers simply puts up another perspective: when n tends to infinite, the probability thath the sum of the random variables divided by n tends to mu is one.\par
Generating Random Numbers\par
Dario Malchiodi's "Simulation Book" is the reference. Why are we so concerned about those random numbers? And what is a random number? \i Happening, done, or chosen by chance rather than according to a plan\i0 . Our machines behave in a deterministic way, usually. So how can we pretend to have something happening by chance rather than according to a plan? Neumann says: \i anyone who considers arithmetical methods of producing random digits is, of course, in a state of sin\i0 . So what we do instead is producing pseudo random numbers. That is, numbers that seem to be generated randomly but really are generated in a deterministic way. Let's try to simulate the throwing of a dice.\par
def middle_square_generator(seed=1461, n=1):\line\tab if (n==1): return(seed)\line\tab curr_val = seed\line\tab v = list(range(n))\line\tab for i in range(n):\line\tab\tab v[i] = curr_val\line\tab\tab curr_val = int(((curr_val ** 2) % (10 ** 6))) // 100\line\tab return v\par
Tutorial on agent based modeling (friday).\par
\par
Lezione 7 - 25/03/2022\par
Today we'll start some tutorials on the use of descriptive modeling. Together with it, we'll take care of the use of a real world simulation software: Anylogic. We'll cover the simulation paradigms covered in the first lesson by this examples developed together, in this professional software. \line Anylogic can be used as a development environment and middleware (?). \par
Timescale we expect our model to have: resolution of our model.\line Situation we want to model: technology company\line Which descriptive paradigm should we use? It sounds reasonable to have stocastic elements in our model. A random variable that can tell us the expected value of the ADS we need to use? boh.\line Paradigm selection: very difficult at the beginning. It depends on the data we have at our disposal. We could model individuals that interact with each other: this is agend based modeling. So we want to model the environment/logic in which the agents act and the agends themselves. \line First of all, we should define the agent types in our system. The main can be thought as the environment agent of our model. \line With 10% probability, our individuals will start considering the corporate technology. \line Layout type: random. Place the individuals randomly on the assigned space.\line Trigger by RATE: how anylogic handles transitions in a state machine by random chance. It's the probabilty that an individual will fire that transition. It can be seen also asa the number of times the transition is fired each (day/second/week...). If it's below one, it's a chance.\par
Control space (in java code): suggestions and auto completions.\par
\par
\par
\par
\par
\par
\par
\par
\par
}
 