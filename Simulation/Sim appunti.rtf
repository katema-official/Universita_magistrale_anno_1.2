{\rtf1\ansi\ansicpg1252\deff0\nouicompat\deflang1040{\fonttbl{\f0\fnil\fcharset0 Calibri;}}
{\*\generator Riched20 10.0.22000}\viewkind4\uc1 
\pard\sa200\sl276\slmult1\qc\f0\fs44\lang16 Simulation - Appunti\par

\pard\sa200\sl276\slmult1\qj\fs22 Lezione 1 - 01/03/2022\par
Alberto Ceselli. What is simulation? Each time we see something in a computer, it is simulated. The question is: how do I make computations out of a simulated object? For the Oxford Dictionary, a simulation is "the production of a computer \b model \b0 of something, especially for the purpose of study". With something, we usually mean a real world process. So, the simulation deals with? 3D objects? graphics? Something to study? Parallel worlds? In our course, simulation will be a descriptive model. We want to pick a real world system and produce a representation, a simulation, of it. For handling such a system, we need a descriptive model of the system. We can use a function to describe the trajectory of the ball. So, descriptive model: we go froma  complex system to a matemathical representation (simpler) of it. Now, models have different models. Different systems implies different types of models. Like, imagine describing a line of people that is waiting for a service. Another important part is wether the system we want to simulate is deterministic or not (most of the time it is not deterministic). In those cases, we just considers the parts of the system that are interesting for us, then we approximate it and define the connections between it and the rest of the world and then apporixmate some details with a stocasthic component. A descriptive model is usually a formula that, given some variables, describe the model.\par
We need descriptive models, that are languages, to tell to a computer the details of a complex systems. We use them to replicate the details and tell the pc the details of the system. So, the second aim of our course will be to use simulations to study systems and evaluate the results. Why doing simulation though? Because by modeling a certain system, we are forced to have a clear understanding of the system, and so we understand it better. We also have a cheap way to make experiments on that model, and those experiments will resemble the ones we'd do on the real world (but in the sim they are cheaper). We can also visualize the behavior of the system when a parameter changes (what-if analyses). Or we can do the same thing by even changing the whole model for the system. We can use it also to visualize results for complex methods. We also have to consider that the results we get in the simulation can be different from the ones in the real system.\par
After the model has been built, we can get algorithms to do something with our model. Sometimes, they give to analytical problems a solution in closed form. Also, what-if analyses are good when there are not too many cases to test. [A prescriptive model is: given a model and a goal, tell me the best behavior].\par
A basic simulation is the Game of Life (Conway, 1970). First observation: a model must be precise about the description of its system. We modelers will use a simplify assumptions: the individuals live in a matrix. In each cell, there is either an empty or full space (no individual or one). Another observation: do we take time into account? How? In this case, both space and time are discretized.\par
Now, we want to get this model into a computer and see something running. We want to answer some questions, for example.\par
How do we make sure that repetition of stocastic simulations make sense overall?\par
In a simulation, we are interested in qualitative and quantitavie analysis (it depends on the simulation).\par
The simulation paradigms that we will see in this course are: discrete events, agent-based and system dynamics. On the practical side, we'll analyse those three paradigms. All of them contain a stocastic component, on their inner part. \par
Discrete events: the system proceeds at steps, discrete steps, and during those specific points in time we have some interesting things that can happen. \par
Agent-based simulations: we imagine that the agens are independent one another. Each of them has a certain logic, and simulationg means to have them comunicate to do more complex things.\par
System Dynamics: we model our system with stocks, flows, delays and feedback loops. \par
We'll see mostly how to use, but also how to build, a simulation. \par
Sheldon M Ross "Simulation", 5th edition, elsevier pubs (2012).\par
acesellis.ariel.ctu.unimi.it\par
\par
Lezione 2 - 08/03/2022\par
Tre modelli: descrittivi, predittivi, prescrittivi (?).\par
Qui ci interessano quelli descrittivi.\par
Random Variables. Last time, we discussed about descriptive modelling: the idea of trying tor eplicate the behavior of a real system in a computer by means of models representig its key features. Simulation is the idea to exploit those descriptive models to perform, on a PC, checks that we would otherwise do on a real system, and would cost more. There are different phylosofies to build models, and we'll see three techniques, all based on the idea we can approximate the behavior of a complex system by a stocasthic component. So, we'll see three paradigms for modeling using stocastic components. Today, it will still be in part an introduction to the course, but also an intro to the discrete events models. So, let's start with an example. Let's think about y = f(x). How many variable there are here? Two, x and y. It's just an equation, and for the modeler this equation has a special meaning: x is the input data/parameters, that is, something i know or can mention or rely on, thati I image to be meaningful for my experiments. f is the description of a process. y is an abstraction of the process modeled by f. So, y is representing the abstraction of the process modeled by f. f is modeling a process in every bit of detail. Given x, f gives as ouotput something, the result of an observation of our system. We are missing something on f: when we apply it to x, we might get some observation out of the model. In a deterministic world, we call x and y a pair of dependent or independent variables. In our case, y depends upon x. y is called a random variable. We want to look at y as something that is independent from f and x. For traditional variables, when we observe them multiple times, we see a value, a number. For a random variable, when we observe it multiple times, we observe different values/numbers. But different values don't mean white noise. According to f, how we model systems, y becomes a random variable that models something. Sometimes we can define f easily starting from some rules, sometimes it is not so simple. Our goal is anyway to put together rules to obtain f. The overall result of our descriptive modeling of a system is a huge random variable, generally speaking. Our descriptive models will give us random variables that are huge, complex. (the example is taken from the Simulation textbook) (introduction 2 page 23, pharmacist).\par
Our descriptive modeling consists on giving a description of the system, and the descriptive model is just our random variable. Our description of the system is f. To answer different questions, we will have to measure different points of our models, that introduce different random vaiables, one for each question. The model we build, anyway, is constructed based on the questions we are trying to answer. Can we build a deterministic model out of those specifications? The answer it's kind of phylosofical. If I know all the possible positions of people in the world and their need, I can. But practically, I can't. So, we want some averaged values. We have to approximate parts of our system. There are two main point where we do those approximation. One point is the link of our system to the outside world. We want to model a system, the pharmacy, that is linked to the outside world. So, let's approximate the connectors of the system to the outside world. Second point to approximate: the details of the system otself that are not crucial for our study. For example, we are not specifically intereset in the process of making a prescription: I just want to know how long does it take to do that. But how do we approximate those things? by means of other, simpler, random variables. So, for our model, we define the system, we find the connectors and define them as random variables. We then define key components of the system as random variables, that will define those components. In our example, we'll have a random variable that will model at which our does the pharmacist go back home. \par
A connector here can be the process of prescriptions arriving to the pharmacy (Prescriptions arriving). The "filling in process", instead, is something that models our process of filling a prescription. Now we have to transform the labels into some matemathical entities, like random variables. A common assumption is that the individuals of the outside world act randomly. If I observe that a prescription has arrived, I can't tell that another prescription will arrive soon. Each prescription comes independently from the others. The number of arriving prescription is an exponential random variable (let's take it for good rn). The good thing is that they are very easy to simulate, we have efficient algorithms for them. Now, let's take a look to the filling in process. What variable is it? A gaussian one? We can assume it. So, the filling in process if or us a normal random variable. We also know a lot of things about them. We can simulate them too. \par
The time between one and the next is how we model our "prescription arriving". The filling in process, instead, is the time it takes to complete one prescription after starting to work on it. \par
\par
Lezione 3 - 11/03/2022\par
Descrittivo, predittivo e prescrittivo. Simulation, AI e RO (per Davide). \par
Connectors are used for the arrivar of prescriptions, for "internal" things... we don't know an appropriate term. \par
We were in the middle of an example of a descriptive model and simulation task. We want to answer some questions starting from some facts. We can't model the description fully: we have to approximate the model. To approximate, we use stochastic components, for connectors to the outside world and processes. \par
Discrete event modeling: interesting things happen only in specific moments in time.\par
In this course, we will first build the model and then analyze the result.\par
Question 5: what if analysis.\par
\par
Lezione 4 - 15/03/2022\par
\par
Introduction ot Probability and statistics for engineers and scientists (Sheldon M. Ross, book). Idk why it's here (even if I imagine). \par
Discrete Event Simulation - Our first kind of approach for describing a certain environment. The connectors and inner components of the model we've seen are described as random variables for example. \par
Recall: when handling probabilities, we first of all imagine to have a Sample Space, that is, all the possible outcomes of an experiment. An Event, instead, is a particular outcome (or a set of outcomes) of the Sample Space. Also the ideas of Complement of an Event, union and intersection of sets and mutually excluusive events are important for probability and statistics. Two events are mutually exclusive if their intersection is empty. If some events are mutually exclusive events, then the probability of their union is the sum of their probabilities.\line Conditional probability: P(A|B) = probability of A to happen knowing B happened before. It is defined as the probability of A and B happening divided by the probability of B happening. \line Also, P(A) = P(A|B)P(B) + P(A|notB)P(notB). The conditioning events (in this case, B and notB) MUST be such that the sum of their probabilities is one, and they ALL must be mutually exclusive.\par
y=f(x). For a modeler, x is input data, while y is an abstraction of the process modeled by f().\par
Random variables: say you have an experiment, whose output is X. X is a variable, assuming to contain the result of your experiment. If the experiment involves some stochastic behavior, the content of X will always be uncertain. X, then, is called random varibale, that can be discrete or continuous. It can be a single outcome or a set of outcomes. \par
Cumulative Distribution Function: a function F(x) = P(X <= x). [Cumulative because the probabilities sum up, they cumulate!!!]. If X is discrete, we can define another function, the Probability Mass Function: p(x) = P(X = x). The sum of all p(x_i) for all i is 1. In the case of a continuous X variable, we have a (non negative) Probability Density Function such that, for C in R, P(X belongs to C) = Integrale su C di F(x) dx.\par
\par
Lezione 5 - 18/03/2022\par
We are revising elements of probability and statistics. Next friday, anylogic for agent based simulation. So, independent event and independent random variables. We say that two events are independent using the terms of conditional probability. A and B are independent if P(A|B) = P(A). That is, B doesn't give me any information about the happening of A. For example, the flipping of the coin: the second flipping is independent from the first. \line Independent Random Variable: they are defined in terms of independent events. They are independent if P(X belongs to C, Y belongs to D) = P(X belongs to C) * P(Y belongs to D).\line\i Questions, comments...? good.\par
\i0 With the random variables, we can make computations. We can build CDF! Mass, Density... and also some particular parameters. The most famous one is the so-called \b expected value\b0 . E[X] is the sum of all the n possible different values that the variable can take times the probability that the variable will have that value. We have a similar definition for the continuous random variable, where, instead of a sum, we have an integral. The Expected Value is a measure about the tendency of the variable. The Expected value has some important properties: the first one is linearity. That means that E[a*X + b] = a E[X] + b. And E[sum from i=1 to n for X_i] = sum from i=1 to n of E[X_i].\line And also, if g() is a generic funxtion, E[g(X)] = sum from i=1 to n of g(X_i) * p(X_i).\par
Expectation is not the only parameter we compute about random variables. another important parameter is Variance. The Variance is a dispersion measure, not a central tendency as E. Basically, it tells me how far i can expect to find single expectations of my random variable from the expectation. Low variance means: repeated observations of a random variable will produce similar results. High variance means multiple observations of the variable will hold more different values (all around the expected value). Median, Mode etc.. are other Expected Value parameters. And there are "variants" also of the Variance (lol), that is, measures of the dispersion of a single random variable.\line If the E of X is mu, the variance is defined as the error that i get by measuring X and confronting it in respect to mu.\par
Covariance: Cov[X, Y] is higher when the two variables are "very similar", that means, then X is high, Y is also high. Same goes for low.  [Michele: The covariance tells us about not how one interacts with each other, but how they behave in respect to their respective Expected Value]. The Covariance instead is low when the two variables are "opposite": when one is high, the other is low. When the two variables are independent, the Covariance is 0.\par
Normalization of the covariance is called Correlation:\line Corr[X,Y] = Cov[X,Y] / sqrt(Var[X] * Var[Y]). This value always falls between -1 and 1. It does not contain any "new" kind of information in respect to the covariance. It's just scaling the Covariance. 1 = Perfect coorelation of the two variables. If one is high, the other one is high. Same for low. -1 = Perfect opposite correlation of the two variables. 0 = the two variables are not correlated. Knowing one doesn't tell me anything about the other. \par
Markov's Inequality: say X is a random variable, an arbitrary one, assuming it takes only nonnegative values. Then, for any constant a > 0: P(X >= a) <= E[X] / a\par
Chebishev's Inequality: if X takes only nonnegative values, has expectations mu and variance sigma^2. Then, for any k > 0,\line P(|X - mu| >= k*sigma) <= 1/k^2\par
the probability of finding this difference to be large is not arbitrarily large, but instead is bounded. The further I go from the expected value, the lower my probability of having that outcome. The larger the sigma, the lower the k we need for reaching a bound (1/k^2) that is large. \par
\par
Lezione 6 - 22/03/2022\par
The idea behind the theory we are studying is that those stocasthic models are in some awy useful, or, at least, affordable (affidabili). We can use them in our models. In general, knowing the distribution of a function can be enough. But usually, central tendency and dispersion (for us, Expected value and Variance) are important as well of course. The complex variables we'll see in our models will be complex results that can't be expressed analitically. \par
Law of large numbers (weak). Let's consider a sequence of random variables X1, X2, ..., Xn. The type of this random variables is not important (we don't care about their distributions). Let's just say that they are independent and identically distributed (so, the distribution can be whatever, but that distribution must be applied to all those variables). [i.i.d. = indepentend identically distributed]. Even if I don't know the distribution i'm good to go, as long as all random variables have the same distribution. Well, that said, for any eta > 0, and if mu is the expected value of one of those variables [conclusions after sorry] (they have the same identical distribution). Mean vs expected value: mean is the sum over n of Xi all divided by n. Is basically the mean of the red values. Conclusion: the probability that this difference is higher than eta goes to zero as n tends to infinite. This concept comes into play when my random variables X1, ..., Xn are really n readings of the same random variable, or n outcomes of the same experiment. The more experiments we do, the more the mean value we compute matches the expected value of the "basic" random variable. The strong law of large numbers simply puts up another perspective: when n tends to infinite, the probability thath the sum of the random variables divided by n tends to mu is one.\par
Generating Random Numbers\par
Dario Malchiodi's "Simulation Book" is the reference. Why are we so concerned about those random numbers? And what is a random number? \i Happening, done, or chosen by chance rather than according to a plan\i0 . Our machines behave in a deterministic way, usually. So how can we pretend to have something happening by chance rather than according to a plan? Neumann says: \i anyone who considers arithmetical methods of producing random digits is, of course, in a state of sin\i0 . So what we do instead is producing pseudo random numbers. That is, numbers that seem to be generated randomly but really are generated in a deterministic way. Let's try to simulate the throwing of a dice.\par
def middle_square_generator(seed=1461, n=1):\line\tab if (n==1): return(seed)\line\tab curr_val = seed\line\tab v = list(range(n))\line\tab for i in range(n):\line\tab\tab v[i] = curr_val\line\tab\tab curr_val = int(((curr_val ** 2) % (10 ** 6))) // 100\line\tab return v\par
Tutorial on agent based modeling (friday).\par
\par
Lezione 7 - 25/03/2022\par
Today we'll start some tutorials on the use of descriptive modeling. Together with it, we'll take care of the use of a real world simulation software: Anylogic. We'll cover the simulation paradigms covered in the first lesson by this examples developed together, in this professional software. \line Anylogic can be used as a development environment and middleware (?). \par
Timescale we expect our model to have: resolution of our model.\line Situation we want to model: technology company\line Which descriptive paradigm should we use? It sounds reasonable to have stocastic elements in our model. A random variable that can tell us the expected value of the ADS we need to use? boh.\line Paradigm selection: very difficult at the beginning. It depends on the data we have at our disposal. We could model individuals that interact with each other: this is agend based modeling. So we want to model the environment/logic in which the agents act and the agends themselves. \line First of all, we should define the agent types in our system. The main can be thought as the environment agent of our model. \line With 10% probability, our individuals will start considering the corporate technology. \line Layout type: random. Place the individuals randomly on the assigned space.\line Trigger by RATE: how anylogic handles transitions in a state machine by random chance. It's the probabilty that an individual will fire that transition. It can be seen also asa the number of times the transition is fired each (day/second/week...). If it's below one, it's a chance.\par
Control space (in java code): suggestions and auto completions.\par
\par
Lezione 8 - 29/03/2022\par
Random Number Generation in deterministic computers is indeed strange. An experiment that was done was the Random Number Table, where 10400 numbers of four digits were taken at random from the British bla bla bla. Anyway, some researchers like Von Neumann started to think about machines capable of producing these Random Number Tables. The first attempt was the middle square generator. Starting from a seed, this algorithm would generate a sequence of random numbers. The idea was: take a seed, compute its square and then look at this value as a sequence of digits. Take the digits that stay in the middle of this sequence, the four middle ones. And use this number as another seed. Claim this to be random. In this way, given a seed, we can generate a random sequence of numbers. But are all of those sequences good? Of course not, some of them don't look random at all. \par
p = list(range(len(v1)))\par
import matplotlib.pypolt as plt\par
plt.scatter(p, v1)\par
Anyway, other aglorithms were invented, like the Congruential Generator, that works like this:\line x_0 = s, x_i+1 = (a*x_i + c) mod m. a, c, and m are user defined parameters, while s is a seed. The main drawback is that the sequence tends to repeat. Can we gen some good properties out of it though? Yes, for example getting the maximum period: the number of steps in my sequence after which the sequence starts repeating. Since the rule is deterministic, when we meet a number in the sequence we've already met, we will obtain the same sequence we've already met. \line In literature, we do know some settings for the parameters of the congruent generator to produce a full period. This means that the sequence we will produce is long m.\line\b Knuth 1981\b0 : A mixed Congruential Generator has full period for all seed values if and only if:\line -m and c are relatively prime.\line -a-1 is divisible by all prime factors of m.\line -a-1 is divisible by 4 if m is divisible by 4.\line However, we usually want something nice to produce for our machine, for example, always numbers (random) with a certain amount of bits.\par
Is having high period enough? Not really. We can have full period Congruential Generator with numbers that are not really random. Predictability is not something we expect from a random source. So, we'd like our random number generator to be unpredictable as a random source would be. \par
Ripley test: it says, say you have a random sequence. Let's look at the differences bw this sequence and the same sequence shifted by one. Or better, we use your sequence as x values, while the shifted one becomes the y values. \par
Let's take the values generated by our RNG as readings of a random variable. When using random generators in applications, we'd like to have readings of the random generator like independent random variables. So, it's up to me if, for specific cases, my application should have some linking between the random variables. Wow, the relationship between random variables and random number generators is stronger than i Thought.\line We can use Covariance or Correlation to check if two Random Variables (and their RNG) are similar or not. \par
numpy.corrcoef(v1[:-1], v1[1:])\par
s6 -> low low correlation! wtf!? The ripley test gives us some feedback (graphic one) that the correlation wouldn't give us. \par
Autocorrelation of a sequence: how is a sequence correlated to itself, if we shift it by a bit and check the correlation between the two sequences?\par
Uniform distribution is the best distribution we can ask for for a completely random variable. So we can ask: does a sequence of random numbers look like a uniform random variable or not?\par
Starting from a random variable with a certain set of readings, can we get the Cumulative Distribution Function (or Empirical Distribution Function)?\par
let's make a function that, given x, gives us F(x) (that is P(X <= x)) \par
def empirical_cdf(v):\par
\tab return lambda y: sum(map(lambda x: x <= y, v)) / len(v)\par
\par
or (more clear, less Cazzola-style):\par
\tab count = 0\par
\tab for k in range(len(v)):\par
\tab\tab if v[k] <= y: count ++\par
\tab return count / len(v)\par
\par
We can get the CDF from the density function with derivation, opposite with integration.\par
if we can get an algorithm that, from a uniform distribution finds a empirical CDF that respects it, i can write another algorithm that takes the Uniform Distribution and transforms it in exponential, normal, ...\par
\par
Lezione 9 - 01/04/2022\par
Agent-based modeling: we've seen an example in Anylogic. It's an integrated environment for simulation models, which is split in three parts. We simulated the diffusion of a technology. We had a corporation trying to get customers in a new market. The corporation is aiming at getting new customers by using advertisements. BUT, at the same time, it can happen that people influence other people on buying this technology by just talking about it to them. We decided to model the system with two types of users: the consumers who may decide to adopt the technology sponsored by the corporation, and the other users using the more underground technology (?) and we started modeling the agent type "consumer". A random variable is what described the probability of our customers to be affected by the advertisements. adStrength has a value associated to it. It is the expected value of the random variable adStrength. \line In AnyLogic, we can also design a visual interface. In the main, we can see the interface. \line Second part of our tutorial: let's model another type of agents. Those adopting the alternative technology.\line From "agent" in the palette you can create a new agent type or even a collection of them.\line This new agent has a chance, every day, of contacting a friend and tell them to change technology.\line A parameter can formally be the expected value of a random variable, or the chance of something happening.\line The new agent will choose a random consumer and then send him a message.\line CTRL + SPACE.\par
Statistics tab in a collection: to obtain data.\par
Pointer "item" in java code: it iterates over the individuals of the population. Item will be set iteratively to each consumer in our list.\par
Analysis -> gives us things to do some statistics.\par
Controls -> allows us to change some parameters dynamically.\par
\par
Lezione 10 - 05/04/2022\par
Pseudo-random generator. We've seen random number tables, that is, tables full of random numbers. We then moved on the idea of generating those tables algorithmically (we generate them as a sequence). We've seen two algorithms for producing this sequences: the Von Newmann's middle square generator and the congruential generator. The congruential generator in particular uses three parameters a, c and m. And also, we have some results from literature that give us settings for those parameters that work well. In fact, one issue we saw was the periodicity of the sequence. When a certain number of the period repeats, the already generated sequence repeats. My numbers are from 0 to m, and I'd like that, after m iterations, i have all the numbers from 0 to m. These are the fully-periodic sequences we're looking for. In literature, we have results that guarantee us this property. In congruential generator, we can achieve those properties. Anyway, theorically speaking, we want our sequences to be NOT predictable. The ridley test tells us how much is this property guaranteed visually. The problem of this test is that it is quantitative, not qualitative (we want a number nzomma). What we can do is the correlation test: let's look at the correlation of the sequence and the sequence shifted by a certain value, as if they were two random variables with a sequence of observations. This can help me understand how independent the two sequences are. \par
p = [numpy.corrcoed(s6[: -k], s6[k:]) for k in range(1,50,1)]\par
Last test we analyze together, which is crucial to understand what happens next, is: let's produce this random sequence. Intuitively speaking, if we assume this numbers to come from the reading of a random variable, which type of random variable we'd like it to be? We want it to be a uniform random variable. We'd like to have a random variable like this because, with those, all values have the same probability of being selected. Next check is: is it true that the sequence we've produced resembles the one I'd get from reading a uniform random variable or not? And, for this checking, the technique proposed is building an empirical distribution function. The Empirical Distribution Function is just building the distribution function we'd have if we had the "true" random variable. \line From a sequence, we can get the Cumulative Distribution Function. We just count! We can use a chart (x = 1 to lunghezza sequenza, y = i valori delal sequenza sorted) to calculate the Cumulative Distribution Function. We just count all the elements that are less or equal than a certain value x, and divide this value by n, and we have the probability. The more the "Empirical" Cumulative Distribution Function approaches a straight line, the more reliable my random generator is (because the values produced are very similar to the one we'd observe from a true uniform random variable). Great, we can now measure the error of our generators in respect to the real random variable we're looking for. This topic of CDF will come back eventually. \line The Glivenko-Cantelli theorem says: If F^ has been computed using a sample of size n drawn from a distribution whose c.d.f. is F, F^ converges in probability to F as n increases. \line Which are the expected properties of a random generator?\line -The period should be as high as possible.\line -The set of generated pseudorandom values cannot distinghuish from an analogous saple drawn from a discrete uniform distribution over \{0,..., m-1\} (no correlation)\line -Its computer implementation should be efficient (i.e. m=2^31 - 1 allows to be encoded with 32 bits).\par
Let's see a straight application of RNG. The so called Monte Carlo methods. The basic idea behind this Monte Carlo models is well described by the anecdote describing its discovery of part of Stan Ulam (read slide).\line The basic idea is measure, count, get probability. \line The idea is: we want to estimate something, but it's hard to come to a model for that thing. Monte Carlo is telling us: draw a bunch of random numbers and count, during those repeated measurements. What you get is what you want: pure and simple. Say we want to compute the value of Pi, pretending we don't know it (Monte Carlo was designed also for this). Let's say that we recall that given a circle C of radius r, its area is Pi * r^2. And we also recall that the area of the smallest square S containing such a circle is (2*r)^2.\line Given those things, let's look at some possible experiments for computing Pi. Let's draw a random point in the square. It can fall inside or outside of the circle, of course. The idea is: let thos points fall, and count how many of them fall inside the circle. \line We do (#points in circle) / (#points drawn). Monte Carlo tells me that this is approximately C/S (The area of the circle / the area of the square) = (Pi r^2) / (4 r^2) = Pi / 4. So Pi is, approximately, 4 * [(#points in C) / (#points drawn)]. \line So, Pi = 4*P[x in circle | x in square]. We don't know this probability, but we can do some measurements to find it out.\par
How many points do I need to put in the figure to get a good accuracy of the value of Pi?\line (The question is) How to have an approximation of Pi which is correct up to \i digit k \i0 with probability (say "confidence") \i at least delta\i0 . [this implies...]\line How large the sample should be?\line Idk, third digit, 100%? let's say 100 points are enough. 16 digits and accuracy of 99%? Probably a lot of points.\par
Computation: Pi = (can be estimated as) (4 * x) / n, where x is the points in the circle, and n is the total number of points.\line Let's consider, or rather define, a random variable Y. \par
def: Y = x / n.\par
def: X = 1 or 0 if... (read following line)\par
Each of this experiments can be 1 or 0. 1 if the point is in the circle, 0 otherwise. The probability of this to be 1 is Pi / 4. The probability of getting 0 is (1 - (Pi / 4)). Now, let's compute the expected value and variance of this Random Variable by applying their definition.\par
E[X] = 1 * (Pi / 4) + 0 * (1 - (Pi / 4)) = Pi / 4.\par
Var[X] = E[(X - mu)^2] = (1 - (Pi / 4))^2 * (Pi / 4) + (0 - Pi/4)^2 * (1 - Pi/4). (???)\par
\par
Lezione 11 - 08/04/2022\par
Let's carry on the example on technology diffusion. We had this corporation trying to push a new technology with advertisements, but there is also another trend that is being shared because of a word of mouth. We saw a Consumer that, after being advertised by the advertisement, becomes interested and eventually adopts the new technology. But it can be convinced by a friend to give up our technology. \line Anylogic allows us to attach Java code to specific callbacks. In fact, simulation models in AnyLogic are Java applications really. \line We want to make analysis out of those simulations. So, we use statistics (non la materia fermo FERMO).\line We linked the statistic of the population of agents to the Time Stack Chart.\line data update -> in Time Stack Chart, has some interesting properties.\par
Today, we'll give a better logic to the agents. The first kind of logic we introduce is swapping of agent type. Consumers may become alternative users and viceversa. \line To model a choice in Anylogic, we have the Branch in the statechart.\line ChangeProbability of consumer: the chance that it changes from being our customer to a supporter of the adversary technology.\line The condition for triggering the conditional state is the result of reading a random variable. The one we'll use is the Bernoulli Random Variable. It can assume two values: 0 or 1. We assume one of the two values with a certain probability x, and the other one with probability 1-x. Bernoulli random variable can be modelled using randomTrue in a condition statement.\line In AnyLogic, try always to think in terms of random variables and their readings, and not "ok pick a random value bw 0 and 1. if its < 0.2 then...".\line In the final state, we want to say: remove one element of this population, and add one to another.\line We also want to model the fact that some persons have a completely different logic: what-if analysis. It's like we are changing the paradigm used to achieve a large reach of the market (Secret Agent).\line Idle: doing nothing.\line Chasing: going to the place where the alternative is and trying to convince it to become a normal consumer.\line Assume that, if a consumer DOES NOT become an alternative, you send a message to an secret agent, that goes to the chasing state.\line In the Alternative, now we send messages with pointers.\line Now, the consumer transition is triggered by a message of ttype Alternative.\line We put a variable (is exactly like a property, but it is explicitly says that it is dynamic) in the Consumer class. We use it to store the message.\line msg is a keyword for the content of the current message.\line We send the current sender to the secret agent.\par
We can make an agent move in space in anylogic.\line move + something to move the agent.\par
Agent arrival: last type of transition. It really refers to an agent moving in space. \par
How to know some rsaesults at the end of the year?\line Connectivity block: text file for having a log.\line Event in agent palette: triggering of something. Cyclically, one per day, print a line of informations in the logfile.\par
\par
Lezione 12 - 12/04/2022\par
Summarising... we were talking about Monte Carlo models. We used them to find out the value of Pi given two areas: one about a square and one about a circle inside of it. We emasure the probability of having a random point inside the circle or outside of it (but still inside the square). If we repeat this process (ipothetically speaking) for all the possible points in the square, we actually compute the ratio of the areas, and can find out the value of Pi. But anyway, even if we don't take all points in account, we can easily end up with a value close to Pi.\line Btw, if we really could have infinite points, we'd have a certain degree of accuracy. The accuracy of the value we compute, the probability of reaching that accuracy and the number of samples we need to reach that probability: those three things are the one we are seeking. \par
So, after doing the calculations in my notes, let's say we can do numerical integration too with this method. \par
So, systems can be modeled, including nontrivial components, in the form of random variables. Statistics allow to reliably run experiments and obtain results by observations on these models. (Pseudo-)Random numbers can be generated algorithmically. The next step is learning when and how to use R.V. from the literature, and generate observations of R.V. algorithmically.\line So, the main families of R.V. are the discrete ones and the continuous ones, and then we have some main techniques for generating R.V., like the inverse transform, the acceptance-rejection, etc..\par
DISCRETE RANDOM VARIABLES we'll see.\line The main problems with RV is remember when to use them. Slide 4 of the lesson about Gen. R.V. gives a table about them. The idea is: I have a phenomena. What's the outcome code of this phenomena? Like, i throw a dice. What's the result? I flip a coin. What's the result? In those cases, we have single value as output with a custom probability (or uniform).\line Sometimes, we are interested in a sequence of events, and as output we have, assuming that each event can be either successful or not, how many successes we've got. So, when we have repeated experiments with success or failure, and the output is "how many times should i try to get a success?". The two big families are: i count how many successes i got and the other is I count how many experiments do I need to get a success.\line How many successes VS how many experiments to get a success(es). \par
FIRST FAMILY (of those two): let's count the number of successes. n is the number of trials i do. n, in most cases, is 1 (i just do one experiment). In this case, BERNOULLI.\line If we instead do n = k trials, we use the binomial random variables.\line What if we use a very large number of trials, like n is very big? We have to use the Poisson random variable.m\par
SECOND FAMILY (of those two): we want to emasure the number of trials to do to get successes. If we want to have one success, we want to measure the number of tests we have to do to get at least one success. n here is the number of successes. If n is 1, i want to get one success. For this, we use the geometric random variable.\line If instead we want k successes, we have to use the negative binomial random variable.\par
LAST FAMILY: up until now we assumed that every experiment was independent from all the others. No link between a trial and the following ones (or the previous ones). But what if instead an experiment has an effect on the next ones? Like, we have a limited collection of elements. How many trials should I do to get k red balls, from a set which has some red and some blue balls? In this case, the probability of getting a red ball at the i-th trial will be affected from the previous results. If in this context we ask: how many red balls do i get by picking up k balls from my sack, that contains n of them? The Hypergeometric random variable does exactly this. Note that the hypergeometric assumes just two possible outcomes, like blue or red in this case. \par
\par
Lezione 13 - 22/04/2022\par
Today we'll start a new tutorial. It's going to be both a tutorial regarding the specific modelling of anylogic, and a tutorial on the third simulation paradigm we'll see on our course, that is, system dynamics. The idea behind system dynamics is not so different from agent-based simulation. Our descriptive model is a composition of agents, each with their own logic, interacting by means of messages. So we have a population of agents, all of the same type and with the same logic. All of them act independently! They can interact thought. The idea of system dynamics is to represent the whole system in terms of expected status. How many individuals are in each state at each point in time? How many individuals change state? We want to answer those questions. So, the idea of SD is to describe the system in terms of "Stocks" and "Flows". We can also aggregate the behaviour of different individuals in an expected overall behavior. I can expect, for exaple, that 10% of the population moves from state Idle to Working in one day. This is because I assume all individuals to be independent. The size of the population is not important anymore. So, we have two semplifications: (1) we can move to an expected overall status (something more deterministic?), and (2) size doesn't matter anymore. There are settings in which those simplifications make sense.\line Example: study of Epidemics. \line They encode (epidemics), usually, a set of states. We'll use the SIR encoding. S = Susceptible. healthy people that is at risk of getting hill. I = infectious and R = Recovered.\line I may say that the rate of how many susceptible people become infected is dependant by the Infectious people. Reinforcement loop: the higher the value of a stock, the more probable it is that another stock will change value. At the same time, the more Recovered people there is, the lower is the value of Infectious people, because we assume that recovered people cannot become Infectious again. So, the more recovered people, the less is the rate of susceptible people becoming infectious. This is a so called Balancing loop. \line InfectiousRate = [intuitively] how many new infectious individuals I'll have to sum to the current value in a certain point in time. \line ExposedRate: more tricky because requires interaction. Let's count how many subsceptible people get contacted by Infectious ones.\line ContactRateInfectious: tells me how many contacts that Infectious person has during a day.\line ProbabilityInfection: the probability that an infectious person will infect another susceptible person.\line Dynamic variable: a variable that is updated during the execution of the system.\line R0: expected number of new infected people produced by a single infected one in his/her all life. For each infected people, how many new infected people I'll have in the next x days? This index is related only to a specific disease. R0 is a static value!\line Rt: the expected number of contagions produced by the first infectious people. So, Rt is the expected number of contagions at a specific point in time in the system. \line\line\line Lezione 14 - 26/04/2022\par
We were discussing about discrete random variables: that is, variables that, once read, give a value in a set. We'll visualise them as integers with some meaning. We saw a first classification for the most famous random variables. Those variables can count the number of successes, the number of trials we need to get a certain number of successes... etc. The Bernoulli Random Variable tells us how many successes we get in a single trial (1 or 0). The Binomial Random Variable tells us how many successes we get in k trials. If the number of trials is very high, we have a Poisson Random Variable. All of those variables count the number of successes as the number of trials increases.\line If we instead want to know the number of trials we need to get 1 or k successes, we use the Geometric RV or the Negative Binomial RV. Also, please note that ALL those trails mentioned are independent one another. But if instead we have situations in which the outcome of a trial affects the one of another, we speak about the Hypergeometric RV, that models the numbers of successes when we have n trials.\line Now, how do we generate values for those Random Variables? We want to produce values that are coherent with those RV. The Inverse Transform Method will help us do so.\par
ITM: pick a random value from 0 to 1 (a prob. value). Assume it was the probability for a certain value in the C.D.F. Which was the value that generated that probability? Use the ITM.\par
Now the problem is: do we know how to generate the probability values at random? Assumption: each probability value is equally like to appear. I only need to sample one of the probability points uniformly at random. We know how to do it! \par
We assume that the random_generator() function generates a random value r that is really as uniform random value between 0 and 1, as it would be generated by a true uniform random variable that generates values between 0 and 1.\par
Poisson: we have a huge number of Bernoulli trials, but with a very small probability of success.\line\line\line Lezione 15 - 29/04/2022\par
System Dynamics simulation paradigm. The main idea was to formulate systems by terms of stocks and flows. It works well when we have huge population of individuals acating in the same way, which therefore work as if they were agents. Modelling the sistem becomes: i choose the stocks, the possible transitions and the transition rates. We used this model to model a pandemic phenomena. The rate in which people from exposed becomes infectious was Exposed * (1/ExpectedIncubationTime).\line A property of the arrows is polarity, that can be positive or negative. It refers to the fact that that factor contributes positively or negatively to the formula. If we have a - sign loop, it is a balancing loop. Otherwise, it's a reinforcement loop. Flow arrows (the white ones) too count as positive arrows. Reinforcement loops have to effect to make the flow go faster, balancing loops make it go slower. \line Forward-positive polarity\line Forward-negative polarity\line Backward-positive polarity\line Back-ward-negative polarity\line These are all the four possible combinations of how an arrow is traversed. Along its direction or in the opposite direction, and if it has a positive polarity or a negative one.\par
We assume that the values we have in our problems are given, and we build the model. But sometimes I want to estimate some values, some parameters, out of some data. \line Suppose you are at the beginning of pandemic, and you don't know some values. You can control the ContactRateInfectious time. If I get out some results out of different models in which this value changes, I can understand what is the best choice. A way to perform the analysis is the Parametric Analysis of the model: we run the model different times with different parameter values and look at what is changing.\par
the "root" parameter is present in every experiment/simulation, that allows us to refer the original model of the experiment.\par
For a what-if analysis, we can look at the loops in the model. We want to introduce vaccines? Good, we can introduce new loops or variables to the model. The more vaccinated, the less susceptible people.\par
parametric analysis: we just change the parameters of the model.\par
what-if analysis: we also change the model of the system itself.\par
\par
Lezione 16 - 03/05/2022\par
We wwere discussing about RV, their structure and how to generate them (and of course how to use them). Basically, we started discussing famous RV, and for remembering how to use them during modeling, a good way can be to think about the category of discrete RV with a custom Probability Mass Function, which include also the uniform one. So, we have RV used to count the number of successes and others used to count the number of trials we need to have a success. With Bernoulli, we have one trial. With binomial, k trials. With Poisson, a large number of trials. To generate them, it's enough to exploit a single principle, the Inverse Transform Method. The ITM tells us: if you have your RV and its CDF, compute the inverse of this CDF, and then draw a random value from a uniform distribution from 0 to 1, and take the value produced by this ITM for your value.\par
Now we look at the geometric RV. \par
\par
Lezione 17 - 06/05/2022\par
Multi-paradigm model. We will combine agents with discrete events.\line We will specify the logic of each agent with discrete event modeling, this is the idea. Application context: food delivery.\line Let's create an agent for each of our entities in the model.\line Agents in AnyLogic live in a certain space. By putting a GIS element, the referent space becomes this GIS space. The first agent we create is the restaurant.\par
\par
Lezione 18 - 10/05/2022\par
We were discussing about random variables. Our survey is almost over. We hust need to go throught the hypergeometric. It's a RV that is different from the previous ones, and it's used to model situations in which the population is somehow limited. But each trial is somehow changing the referenced population. The setting is the following: we have a population of individuals, blue and red ones. We consider as successes the drawing of a blue ball from the box. We repeat this operation n times, but after each trial I KEEP my ball out of the box (the individual out of the population). My question is: how many blue balls do I get by repeating this trial n times? As parameters, this RV has the size of the population N+M (N hold a certain feature, M do not) and the number of checks, n. Reading the hypergeometric RV is like reading the number of times over this n experiments in which you get an individual holding your feature. The formula is given in the slide, we won't cover it in detail. \par
Let's now move to the universe of RV. Those variables produce real values. Let's talk about Uniformly Distributed (Continuous) Random Variables. A good way to visualize them is through their PDF (probability distribution function), where x = values the RV can assume, y = Probability that they do. In a UDRV, each value has the same probability of being drawn. The question now is the following: how do we generate values for this random variables? The Inverse Transform Method could help. The main principle behind this method is: I take the PMF but I don't use this straightly. I take the probability as x, i generate it randomly from a function that generates uniform values between 0 and 1, and I output the corrisponding value. Can I do the same here? In a certain sense, yes. I can move to the Cumulative Distribution Function by calculating the integral of my f(x).\par
If you want the memoryless property, you have to use the exponential RV. \par
Suppose you have multiple units (components) for a machine. Each of them has a lifetime modeled by an exponential random variable, each with different lambda parameters.\par
phi for Normal RV: Repositioning by mu and rescaling by sigma^2.\line\line\par
Lezione 19 - 13/05/2022\par
Let's continue the rider application.\par
We were reasoning about the flow of actions between agents. We have observed that, differently from our previsous example, datas need to be exchanged using those messages. So, we need to finish setting up the structure of the model, and then focus on a specific part of the model: the working of the restaurant. Its logic right now is very simple.\par
If an agent is moving and a message arrives, the message is lost.\par
An "event" is something that is triggered at runtime. eventCustomerCall models a random call from a customer.\par
add_customers() -> add_ "something in the main"\par
To avoid lost messages, we can either add them to a queue or sending the messages just to the available riders.\par
Sometimes, we need a model inside another model.\line\line\line Lezione 20 - 17/05/2022\par
We've seen the memoryless property of exponential RV, that is very important and interesting. \line Say you have n phenomena happening in parallel, and each of them is modeled by an exponential random variable. Then, the minimum of their values, which is again a random variable, is exponential. [La sommatoria sulle i \'e8 da 1 a n]\line Now, Normal Random Variable.\line We have expectation mu and variance sigma^2. Why are they called normal? Maybe because of the Central Limit Theorem (correlazione tra le due cose???). Let's take a sequence of n independent and identically distributed ranmo variables with finite exp. value and variance simga^2. We can prove that their sum tends to be a normally distributed rv as their number tends to infinity. In a sense, normal RVs model every phenomena we observe, given that they are the sum of n random phenomena.\line We might be interested in rescaling a normal random variable to have mu = 0 and var = 1 in order to generate random values for it. Then, we can rescale our RV!\line New principle: Acceptance-Rejection (method), introduces by Von Neumann. It says that:\line say you have to generate a R.V. X with p.d.f. f(x). But generating the cumulative from f(x) is problematic. Ok, so, say you have another R.V. Y with p.d.f. g(y), and we know that it's easy to generate. \line Say that X is a Normal RV, while Y is, idk, an Exponential RV. And you know that those two might be linked. In particular, you know that f(y) / g(y) <= c, where c is a certain constant, and this holds for every y. Now, you can:\tab\line -Generate a vaule y vor Y (from g(y))\line -Generate a value u vor a uniformly distributed RV "U".\line -Then, we check: if u <= f(y) / [ c * g(y) ], then we output X = y\line -Otherwise, repeat.\line The values we produce are valid values for X (are consistent with its p.d.f.), and c is the expected number of iterations we need to converge.\par
We have another principle: the Composition principle. If you have a RV X that needs to be generated with a C.D.F. F(), and F() can be decomposed as a linear sum of other functions with a particular property, then we can generate F() in a certain way.\line First, generate a value j for a (discrete) R.V. whose p.d.f. is given by a_i.\line Generate a value of a R.V. whose C.D.F. is F_j()\par
Poisson Processes\line It's a process for which several rules apply. There are SEVEN rules, 7! So, the rules are:\line 1) Events occour at random time points.\line 2) Say you can count the number of events in the interval [0, t], and that is N(t).\line 3) The number of events at time 0 is 0, or N(0) = 0.\line 4) The number of events in disjoint time intervals are independent (independent increment assumption).\line 5) The PDF of the number of events in a given interval depend only on its length, not on its position (stationary increment assumption).\line 6) in small intervals, the probability of an event to occur is approximately h * lambda. \line 7) the probability of having 2 or more events in a small time interval tends to 0.\line What do Poisson Processes model? Processes where events occur independently one another. For example, customers that come in my shop, rain drops that fall in a specific area...\par
\par
Lezione 21 - 20/05/2022\par
Let's replace the Agent representation of the restaurant in a Discrete events model, because we are interested in the processes that happen there. The interesting events are those that make us transition from a state to another. Let's develop the process model for the restaurant and let's give it a UI for monitoring what happens. \line\line\line\par
\par
}
 